{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e408ff-907f-4ef5-ae6a-37c755bc26d4",
   "metadata": {},
   "source": [
    "![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2FApplied+GenAI&dt=Understanding+LLMs.ipynb)\n",
    "\n",
    "# Understanding LLMs\n",
    "\n",
    "A quick experiment to illustrate what an LLM is actually doing\n",
    "\n",
    "Take a well known passage of text, like the first paragraph from \"A Tale of Two Cities\" by Charles Dickens and Harvy Dunn, 1921:\n",
    "\n",
    ">It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way--in short, the period was so far like the present period that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\n",
    "\n",
    "Imagine you are the author and have started writing this paragraph.  How likely is it to end up with these words?\n",
    "\n",
    "You start with 'It'.  That narrows down what comes next.  Given all of the text samples an LLM is trained on we can detect the most likely next word and it is 'was'.  \n",
    "Now start with 'It was'.  What comes next?\n",
    "\n",
    "How long before we start with enough that the LLM can actually decide the mostly likely continuation is the exact same passage?  After just 5 words the LLM can recite the remainder of the paragrph as the sequence is that unique!\n",
    "\n",
    "Since the LLM was trained on a large amount of text that most certainly contained this very popular book that is also in the [public domain](https://www.loc.gov/item/05000749/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680587e-b7ff-4745-8ae8-25ed8274ffb4",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Understanding%20LLMs.ipynb) and run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdcad757-568c-40fb-8cf6-200969971337",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d35703-a49e-4663-b2be-4c6d0a412aee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6411dca4-d373-4758-8b7e-70fe0c694317",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment.  Also, the APIs for Cloud Speech-To-Text and Cloud Text-To-Speech need to be enabled (if not already enabled)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b61fe-8e5a-4007-9635-fd891d1786ef",
   "metadata": {},
   "source": [
    "### Installs (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91266905-279d-43c6-baed-5a800a3acf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "install = False\n",
    "try: import google.cloud.aiplatform\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-aiplatform (VERTEX AI), ... commencing')\n",
    "    !pip install google-cloud-aiplatform -U -q\n",
    "    install = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2f6269-8099-4c3b-8282-797f5b3cc34f",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "390bb3dd-8a57-46eb-9a70-84cc62ad20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c313391-c3fa-41b1-80ca-d7bbd653adcb",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d420e6bb-c0e5-42f9-a777-7e32ac7a9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33ebd4-be60-4812-af0b-00f295af62d5",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf698e18-fede-457f-8f85-3dfe004d55b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f980027-e473-4cab-9cdf-96159cf4cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e6db806-6298-4b82-bb51-3821420cc246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai.language_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d40fc646-06da-4592-897e-b5a1a2730cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e96ca4-5383-47e1-ad12-1fe39bd1a4a7",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup LLM and Predictor Function\n",
    "\n",
    "Connect to the `text-bison` model for text generation.  Then build a helper function around the LLM prediction calls to:\n",
    "- specify how many input words from the known `sample` to pass as input\n",
    "- specify how many output words to ask for\n",
    "- specify how many tries/request to make for output words\n",
    "    - adjust temperature from 0 to 0.1 to see more than just the most likely next word chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a070b10-490f-4ab0-a2f9-124a85a962fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = vertexai.language_models.TextGenerationModel.from_pretrained('text-bison@001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d14262ae-477e-46fd-a6a6-e4ba5fcd71e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way--in short, the period was so far like the present period that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\n"
     ]
    }
   ],
   "source": [
    "sample = \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way--in short, the period was so far like the present period that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\"\n",
    "spaces = [i for i, char in enumerate(sample) if char == ' ']\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2b81a4b0-b52e-4b0a-b180-ad7be311ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(words, new_words, trys = 1):\n",
    "    start = sample[0:spaces[words-1]]\n",
    "    print('The input is: ', start)\n",
    "    print('Correct Next: ', sample[spaces[words-1]:spaces[words+new_words-1]])\n",
    "    temperature = 0\n",
    "    \n",
    "    max_output_tokens = new_words\n",
    "    top_k = trys\n",
    "    if trys > 1: temperature = 0.1\n",
    "    top_p = 1\n",
    "    \n",
    "    if trys == 1: print('Response: ', llm.predict(start, temperature = temperature, max_output_tokens = max_output_tokens, top_k = top_k, top_p = top_p))\n",
    "    else:\n",
    "        for i in range(trys):\n",
    "            print(f'Response {i+1}', llm.predict(start, temperature = temperature, max_output_tokens = max_output_tokens, top_k = top_k, top_p = top_p))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c709556c-585f-4fd0-95a2-e2b30b52abc8",
   "metadata": {},
   "source": [
    "---\n",
    "## Predict the Next Word(s)...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bfb5ac-c0b3-48fe-a43f-2a4cd2a19ebe",
   "metadata": {},
   "source": [
    "Pass 1 word in, ask for 1 word out, try 1 time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5576c7b4-e9ca-4037-b741-2fdf3f06f5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  It\n",
      "Correct Next:   was\n",
      "Response:  is\n"
     ]
    }
   ],
   "source": [
    "predictor(1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0aefec-c8f0-4553-9097-b8ffd1e13ce0",
   "metadata": {},
   "source": [
    "Pass 1 word in, ask for 2 words out, try 1 time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3fe4f8e3-750e-4a4b-81f8-40585b7b1d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  It\n",
      "Correct Next:   was the\n",
      "Response:  is a\n"
     ]
    }
   ],
   "source": [
    "predictor(1, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ccf17-7ccf-4195-a6bb-01bc7edc33e6",
   "metadata": {},
   "source": [
    "Pass 1 word in, ask for 2 words out, try 10 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "be323173-4660-4584-91c8-2f6055842495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  It\n",
      "Correct Next:   was the\n",
      "Response 1 's\n",
      "Response 2 's\n",
      "Response 3 is a\n",
      "Response 4 is a\n",
      "Response 5 is a\n",
      "Response 6 's\n",
      "Response 7 's\n",
      "Response 8 is a\n",
      "Response 9 's\n",
      "Response 10 's\n"
     ]
    }
   ],
   "source": [
    "predictor(1, 2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad9b171-5499-4713-b12d-d4e1bf1f99bf",
   "metadata": {},
   "source": [
    "Pass 1 word in, ask for 3 words out, try 1 time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "856c0f03-8822-4103-95ac-70ef482b9085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  It\n",
      "Correct Next:   was the best\n",
      "Response:  is a very\n"
     ]
    }
   ],
   "source": [
    "predictor(1, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694311a-eb8c-432d-830a-f3836f7bd9a6",
   "metadata": {},
   "source": [
    "Pass 1 word in, ask for 3 words out, try 10 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "29ac4659-b67f-4770-a634-cae7e2c27a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  It\n",
      "Correct Next:   was the best\n",
      "Response 1 is a good\n",
      "Response 2 is a good\n",
      "Response 3 is a good\n",
      "Response 4 is a good\n",
      "Response 5 is a good\n",
      "Response 6 is a very\n",
      "Response 7 is a good\n",
      "Response 8 is a good\n",
      "Response 9 is a very\n",
      "Response 10 is a good\n"
     ]
    }
   ],
   "source": [
    "predictor(1, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2df9a2-d1ab-4d5f-a099-518b39878ce0",
   "metadata": {},
   "source": [
    "## How Many Input Words Are Needed To Correctly Reproduce The Sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd96057-b4fb-409f-9f18-acccc5faddcb",
   "metadata": {},
   "source": [
    "Pass 2 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "74745993-17f6-4962-a2b2-9f0492d97b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  It was\n",
      "Correct Next:   the\n",
      "Response:  a\n"
     ]
    }
   ],
   "source": [
    "predictor(2, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c0d66-e397-4efa-bb85-b848124aa69a",
   "metadata": {},
   "source": [
    "Pass 3 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "346ba61a-c241-41f7-bd41-621d0c9d2445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  It was the\n",
      "Correct Next:   best\n",
      "Response:  first\n"
     ]
    }
   ],
   "source": [
    "predictor(3, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a6d30-d1aa-4528-a7ce-3635de5d3526",
   "metadata": {},
   "source": [
    "Pass 4 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6cf054e7-ece0-4be3-b6af-91b25044a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  It was the best\n",
      "Correct Next:   of\n",
      "Response:  decision\n"
     ]
    }
   ],
   "source": [
    "predictor(4, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5ddf6-bc94-4c36-8375-d18ca43ea026",
   "metadata": {},
   "source": [
    "Pass 5 words in, ask for 1 word out, try 1 time: answer is CORRECT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5aac306c-8473-45c2-95ea-181a3a0fca03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  It was the best of\n",
      "Correct Next:   times,\n",
      "Response:  times\n"
     ]
    }
   ],
   "source": [
    "predictor(5, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e26bf-44e2-4af4-ba2d-bade1fcb94f9",
   "metadata": {},
   "source": [
    "Pass 5 words in, ask for 4 words out, try 1 time: answer is CORRECT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fe4403e3-59d2-44aa-a907-6f41ab33cfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  It was the best of\n",
      "Correct Next:   times, it was the\n",
      "Response:  times, it was\n"
     ]
    }
   ],
   "source": [
    "predictor(5, 4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a5be41-56d9-4204-b0e5-719ee1c1cd4d",
   "metadata": {},
   "source": [
    "Pass 5 words in, ask for 20 words out, try 1 time: answer is CORRECT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ece54493-9880-41d7-8eea-967fd52599bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  It was the best of\n",
      "Correct Next:   times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it\n",
      "Response:  times, it was the worst of times, it was the age of wisdom, it was the age\n"
     ]
    }
   ],
   "source": [
    "predictor(5, 20, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a323708-5602-4816-982a-bdbe9f50b5b9",
   "metadata": {},
   "source": [
    "Pass 5 words in, ask for 20 words out, try 5 time: answer is CORRECT consistantly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f009ad3e-d527-49c6-82a8-baba8155367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  It was the best of\n",
      "Correct Next:   times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it\n",
      "Response 1 times, it was the worst of times, it was the age of wisdom, it was the age\n",
      "Response 2 times, it was the worst of times, it was the age of wisdom, it was the age\n",
      "Response 3 times, it was the worst of times, it was the age of wisdom, it was the age\n",
      "Response 4 times, it was the worst of times, it was the age of wisdom, it was the age\n",
      "Response 5 times, it was the worst of times, it was the age of wisdom, it was the age\n"
     ]
    }
   ],
   "source": [
    "predictor(5, 20, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8da6dc-4ed3-42a3-97c2-8c3b677c5756",
   "metadata": {},
   "source": [
    "## Starting Mid-Sentence, How Many Input Words Are Needed To Correctly Reproduce The Sample?\n",
    "\n",
    "Following the same process as above, but starting inside the first sentence.\n",
    "\n",
    "After 6, 8, and 9 words it guesses the next word correctly but cannot guess the remainder of the passage.\n",
    "\n",
    "After 10 words it is then able to deduce the remainder of the passage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "abcddabc-4631-45ae-9208-07fba13a61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way--in short, the period was so far like the present period that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\"\n",
    "spaces = [i for i, char in enumerate(sample) if char == ' ']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aef689-dc3f-471d-bcec-a854b570f32c",
   "metadata": {},
   "source": [
    "Pass 2 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fadf4aa3-266f-41da-a240-6e61cb832bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst\n",
      "Correct Next:   of\n",
      "Response:  .\n"
     ]
    }
   ],
   "source": [
    "predictor(2, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82ee1d0-f55e-45fe-92f5-bd94e4b66747",
   "metadata": {},
   "source": [
    "Pass 3 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "de042176-bbe9-4d06-b9a7-ed68cdacaff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of\n",
      "Correct Next:   times,\n",
      "Response:  \n"
     ]
    }
   ],
   "source": [
    "predictor(3, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12695b97-b123-4a5c-b623-8e845c7cd9fb",
   "metadata": {},
   "source": [
    "Pass 4 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "65af2b7f-ef36-4687-b1ac-a1573f4ee5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times,\n",
      "Correct Next:   it\n",
      "Response:  the\n"
     ]
    }
   ],
   "source": [
    "predictor(4, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf571e54-2695-40fb-bb10-0a0d88dce54c",
   "metadata": {},
   "source": [
    "Pass 5 words in, ask for 1 word out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1edd89c7-a7c8-4bc1-8d4c-bfe33e12b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it\n",
      "Correct Next:   was\n",
      "Response:  is\n"
     ]
    }
   ],
   "source": [
    "predictor(5, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a41c97-0eea-41dd-b9d7-6bd810b3fe53",
   "metadata": {},
   "source": [
    "Pass 6 words in, ask for 1 word out, try 1 time: answer is CORRECT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f4e85f1c-6867-41b6-b261-c7f689e8db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was\n",
      "Correct Next:   the\n",
      "Response:  the\n"
     ]
    }
   ],
   "source": [
    "predictor(6, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f8700-7c66-499e-bd98-5090f9b996f3",
   "metadata": {},
   "source": [
    "Pass 6 words in, ask for 4 words out, try 1 time: answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "54cd2b9c-c1b8-496c-b17b-e47ef18f9ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was\n",
      "Correct Next:   the age of wisdom,\n",
      "Response:  the best of times\n"
     ]
    }
   ],
   "source": [
    "predictor(6, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ebc6178e-b3aa-41eb-ac09-68a8efe15ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the\n",
      "Correct Next:   age\n",
      "Response:  best\n"
     ]
    }
   ],
   "source": [
    "predictor(7, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "941099a5-d3b2-47a4-b222-d34205f56f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age\n",
      "Correct Next:   of\n",
      "Response:  of\n"
     ]
    }
   ],
   "source": [
    "predictor(8, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1cbc191d-e9cd-46f7-b736-cccf17a1c381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age\n",
      "Correct Next:   of wisdom, it was the age\n",
      "Response:  of wisdom.\n",
      "\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "predictor(8, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "11e60f45-9220-426f-a682-adc1980bfaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age of\n",
      "Correct Next:   wisdom,\n",
      "Response:  wisdom\n"
     ]
    }
   ],
   "source": [
    "predictor(9, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8e4c32b1-195c-4b2e-be09-7f94279a0df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age of\n",
      "Correct Next:   wisdom, it was the age of\n",
      "Response:  wisdom.\n",
      "\n",
      "The best\n"
     ]
    }
   ],
   "source": [
    "predictor(9, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5d5b4e7a-bb8d-4eac-bb75-5bd637c857c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age of wisdom,\n",
      "Correct Next:   it\n",
      "Response:  it\n"
     ]
    }
   ],
   "source": [
    "predictor(10, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "895d6a37-cf8b-4c49-92cb-4f9505287508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age of wisdom,\n",
      "Correct Next:   it was the age of foolishness,\n",
      "Response:  it was the age of foolishness\n"
     ]
    }
   ],
   "source": [
    "predictor(10, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d4dfde8c-3e86-41d8-b44a-2c0a49e8a1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is:  the worst of times, it was the age of wisdom,\n",
      "Correct Next:   it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness,\n",
      "Response:  it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it\n"
     ]
    }
   ],
   "source": [
    "predictor(10, 30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00824c-ad06-4d99-97f3-04d6e19bdafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1723087-34cb-4ff9-9512-e2f460926f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd3567-acfe-4877-8ab4-0bd138756fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff01e78-34c2-4cbf-ab9b-1ae85a925266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8441528c-b049-452d-8fbb-349b8e5e193b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
