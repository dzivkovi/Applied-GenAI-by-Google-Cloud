{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4c572f",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2Flegacy&file=Python+Asynchronous+API+Calls.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/legacy/Python%20Asynchronous%20API%20Calls.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2Flegacy%2FPython%2520Asynchronous%2520API%2520Calls.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/legacy/Python%20Asynchronous%20API%20Calls.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/legacy/Python%20Asynchronous%20API%20Calls.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f1c8a-342f-4828-8269-ddd920b20ec2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**File Move Notices**\n",
    "\n",
    "This file moved locations:\n",
    "- On 10/13/2024 (mm/dd/yyyy)\n",
    "\t- From: `Applied GenAI/Python Asynchronous API Calls.ipynb`\n",
    "\t- To: `Applied GenAI/legacy/Python Asynchronous API Calls.ipynb`\n",
    "---\n",
    "<!---end of move notices--->\n",
    "\n",
    "# Python Asynchronous API Calls\n",
    "\n",
    "Methods for making asynchronous API calls.  Additionally, managing concurrent request and handling errors.\n",
    "\n",
    "To illustrate the concepts, the Vertex AI SDK will be used to make sychronous and asynchronous request for generative AI APIs for Gemini and PaLM.  The concept and solutions for managing concurrency and errors apply to any API with an asynchronous client.\n",
    "\n",
    "The example used below starts with requesting a list of vocabulary words.  This is a good synchronous task because it is really just a single request.  This is followed with the tasks of requesting definitions for each word.  Using a synchronous approach to this would be time consuming.  Switching to an asynchronous approach allows requesting many words at the same time.  However, this introduces the need to manage concurrency - how many simountaneous requests are being made.  As more requests are made the chances of hitting qouta limits increase, especially in a shared environment with multiple application make calls.  The concept of concurrency is also extended to include error handling and retries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0220187f-f83b-4a65-a32d-cbf486d19409",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Python%20Asynchronous%20API%20Calls.ipynb) and run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf9e789-f8d9-455f-9d93-da2f385e8179",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b61850-8266-4f16-a882-86f47fa6a7d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a83d89-4188-4b70-a892-16d384dd1b43",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf908f99-58a6-4c4b-931e-fe413ecdaa45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83729efc-2809-4d62-9ed4-d0a83eb0451c",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc874b0c-c47e-40fa-8042-214a4bee8939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0855d86-5380-403d-ae48-941ce776c98b",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4acaa-da79-44a1-961d-c8874930c223",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed30be3-9541-49f7-b6a9-7e854cffc9e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6192e238-4e5a-47d1-87f0-c436dfdb4661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'tips'\n",
    "EXPERIMENT = 'async-api'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7086341c-3baa-49e3-bac5-1143794f8bf2",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67a11b2-2728-4d51-b3df-2428504a7576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import asyncio\n",
    "\n",
    "import vertexai.language_models # PaLM and Codey Models\n",
    "import vertexai.generative_models # for Gemini Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509e363-d1ec-4c57-9b42-71364e6b4e01",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17802a1f-8df3-46df-9d1f-40ada1a473d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16869614-5a02-47a1-8211-91325e3cd648",
   "metadata": {},
   "source": [
    "---\n",
    "## Synchronous Use Of APIs - Using Vertex AI Generative AI Models\n",
    "\n",
    "To get started, the [Vertex AI SDK for Python](https://cloud.google.com/python/docs/reference/aiplatform/latest) will be used to make requests using the generative AI APIs for PaLM and Gemini.\n",
    "- [Vertex AI SDK for Python](https://cloud.google.com/python/docs/reference/aiplatform/latest)\n",
    "- [Gemini Class Overview](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/sdk-for-gemini/gemini-sdk-overview-reference)\n",
    "- [PaLM Text Model Classes](https://cloud.google.com/vertex-ai/docs/generative-ai/sdk-for-llm/sdk-use-text-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adbef2b-2cc8-4c45-8f54-1204fc6c08e1",
   "metadata": {},
   "source": [
    "### Generate A List of Vocabulary Words - With Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e6d0ee-32f4-4c39-82dc-7f0b681bd23d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Connect to the Gemini Model API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21bb631d-701f-44c7-b00c-2a1b883f1669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemini_model = vertexai.generative_models.GenerativeModel(\"gemini-1.0-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d1440-d3ac-45f3-8511-8d1d37a632ab",
   "metadata": {},
   "source": [
    "Request a list of vocabulary words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a37752e-fc0f-4338-b93a-376afd1ff229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_words = gemini_model.generate_content(\n",
    "    [\n",
    "        \"I need a long list of vocabulary words to study for the SAT.\",\n",
    "        \"Respond with only a comma separated list of words.\"\n",
    "    ],\n",
    "    generation_config = dict(max_output_tokens = 8000, temperature = 0.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "792e5718-f095-45db-a7cc-26452ccf54c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abrogate, abscond, accede, acquiesce, acrimony, adjudicate, adumbrate, affable, alacrity, altruistic, ambiguous, ameliorate, anachronism, anathema, antithesis, apocryphal, apothegm, approbation, arcane, ardor, assiduous, audacious, autonomy, avarice, avidity, avuncular, benign, bombastic, bucolic, capricious, catharsis, circumlocution, clairvoyance, cogent, commensurate, complacence, compunction, condone, conflagration, congruity, connoisseur, contentious, contrite, copious, cosmopolitan, craven, credulous, crescendo, crux, cryptic, culpability, cynical, magnanimous, maudlin, mellifluous, mendacity, meticulous, miasma, myriad, nascent, nemesis, neophyte, obsequious, obstreperous, obtuse, odious, officious, ominous, opulent, opprobrium, osmotic, ostentatious, pacific, palliative, panacea, pandemonium, pariah, paucity, peccadillo, pedantic, penitent, perfidious, perfidy, perfunctory, peripatetic, perspicacious, philanderer, phlegmatic, plethora, poignant, polemic, portentous, prevaricate, probity, prodigal, prolix, propitious, proselyte, protean, protocol, provenance, providential, puerile, pugnacious, pusillanimous, quixotic, raconteur, refractory, refulgent, reiterate, remonstrate, rendezvous, repartee, reprehensible, resilient, resonance, reticent, retrograde, saccharine, sagacious, salacious, sanguine, sardonic, saturnine, scintillating, scribble, scrupulous, sedentary, sedulous, serendipitous, sibylline, simian, sinecure, solicitous, solipsism, somnolent, specious, strident, stultify, sublimate, sublime, suborn, succulent, supercilious, surreptitious, sycophant, taciturn, temerity, temporize, tenuous, tirade, torpid, tractable, transcendent, trepidation, ubiquitous, unctuous, unrequited, uxorious, vacillate, venerate, venial, veracity, verbose, vestige, vicarious, vicissitude, vindictive, virile, vituperate, voluble, voracious, whimsical, zephyr'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_words.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8520df8a-58c8-4a4a-b4ed-9b6311047dfb",
   "metadata": {},
   "source": [
    "Reformat the list of words as a Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d3c4248-f58f-4c90-bff8-9fd1d5ce573b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_words = [word.strip() for word in vocab_words.text.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b3b5f1e-f9f5-4082-99a8-662418c35a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abrogate',\n",
       " 'abscond',\n",
       " 'accede',\n",
       " 'acquiesce',\n",
       " 'acrimony',\n",
       " 'adjudicate',\n",
       " 'adumbrate',\n",
       " 'affable',\n",
       " 'alacrity',\n",
       " 'altruistic',\n",
       " '... (154 more words)',\n",
       " 'vestige',\n",
       " 'vicarious',\n",
       " 'vicissitude',\n",
       " 'vindictive',\n",
       " 'virile',\n",
       " 'vituperate',\n",
       " 'voluble',\n",
       " 'voracious',\n",
       " 'whimsical',\n",
       " 'zephyr']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_words[0:10] + [f'... ({len(vocab_words) - 20} more words)'] + vocab_words[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc5fda-10aa-4932-badb-08978516b033",
   "metadata": {},
   "source": [
    "### Get Word Definitions - With Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6d9096-8743-4a93-80da-8efcdb6bcfdd",
   "metadata": {},
   "source": [
    "Request a definition for the first vocabulary word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34621b4a-942b-42a9-8ff3-0e3805dee493",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Remember Abrogate as \"Rocking the Boat\"**\n",
      "\n",
      "**Break down the root:**\n",
      "\n",
      "* **\"Rocking\"** (ro-): rocking, shaking, or upsetting\n",
      "* **\"boat\"** (gat-): something that conveys or supports\n",
      "\n",
      "**Put it together:**\n",
      "\n",
      "**Abrogate (v.)** means to repeal or cancel something formally, essentially \"rocking the boat\" and upsetting the established order.\n",
      "\n",
      "**Mnemonic:**\n",
      "\n",
      "Imagine a boat that's been firmly anchored. When someone abrogates a law or agreement, it's like they're suddenly rocking the boat and causing it to list or capsize. The consequences can be significant, especially if the boat represents something important or stable.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    gemini_model.generate_content(\n",
    "        ['Describe the word', vocab_words[0], 'in a way that will make it easy to remember.']\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e7f78-ace6-4c98-9f84-49305e5d8c6a",
   "metadata": {},
   "source": [
    "### Get Word Definitions - With PaLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c049779-b93e-421a-bed0-55bc254a24da",
   "metadata": {},
   "source": [
    "Connect to the Palm Model API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c7aad09-fdf0-4283-bf6c-47a0deaef032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "palm_model = vertexai.language_models.TextGenerationModel.from_pretrained(\"text-bison@002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f4132-48de-480a-b44b-52283345bb66",
   "metadata": {},
   "source": [
    "Request a definition for the first vocabulary word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ac167ac-8428-43cf-97d6-820ab8b89586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " **Mnemonic:** \n",
       "To remember the word \"abrogate,\" think of a \"broken gate.\" Just as a broken gate can no longer serve its purpose, something that is abrogated is no longer in effect.\n",
       "\n",
       "**Definition:**\n",
       "Abrogate means to repeal or annul a law, treaty, or agreement. It is a formal term often used in legal or political contexts to describe the official termination or cancellation of a previously established rule or arrangement."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palm_model.predict(prompt = f'Describe the word {vocab_words[0]} in a way that will make it easy to remember.  Then, provide a definition of the word.', max_output_tokens = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8473d35-98c1-4b62-aafc-b494f1ffa16f",
   "metadata": {},
   "source": [
    "### Definitions For Many Words\n",
    "\n",
    "What if the tasks changes to needing to make multiple calls, like requesting the definition for many words.  If the list is short or timing is not important then doing synchronous, one at a time, calls may work.  In the following example the `predict_streaming()` method is so that results appear as they are generated by the API.\n",
    "- [Streaming text generation](https://cloud.google.com/vertex-ai/docs/generative-ai/sdk-for-llm/sdk-use-text-models#stream-text-generation-sdk)\n",
    "- [`.predict_streaming()` method](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models.TextGenerationModel#vertexai_language_models_TextGenerationModel_predict_streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0386cc0c-2d41-459b-b687-794c1cef027f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for abrogate:\n",
      " **Mnemonic:** \n",
      "To remember the word \"abrogate,\" think of a \"broken\n",
      " gate.\" Just as a broken gate can no longer serve its purpose, something that is abrogated is\n",
      " no longer in effect.\n",
      "\n",
      "**Definition:**\n",
      "Abrogate means to repeal or annul a law, treaty,\n",
      " or agreement. It is a formal term often used in legal or political contexts to describe the official termination\n",
      " or cancellation of a previously established rule or arrangement.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results for abscond:\n",
      " **Mnemonic:** \n",
      "Imagine a thief quickly running away from the scene of a crime, leaving no trace behind.\n",
      " The word \"abscond\" sounds similar to \"absent,\" which is what the thief is from the scene\n",
      ".\n",
      "\n",
      "**Definition:** \n",
      "To leave suddenly and secretly, especially in order to escape\n",
      " from danger or avoid arrest.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results for accede:\n",
      " **Mnemonic:** \n",
      "*Ac*cede sounds like \"**a** **see**d**\n",
      ".\"  Imagine planting a seed and watching it grow into a beautiful plant.  This is\n",
      " similar to the idea of agreeing to something and allowing it to happen\n",
      ".\n",
      "\n",
      "**Definition:**\n",
      "To agree to a request, demand, or proposal\n",
      "; to comply.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results for acquiesce:\n",
      " **Mnemonic:** \n",
      "*Acqui*esce sounds like \"I *acqu*ire peace\n",
      ".\"\n",
      "\n",
      "**Definition:** \n",
      "To comply without protest; to agree or consent, usually reluctantly.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results for acrimony:\n",
      " **Acrimony** can be remembered as \"**A** **cri\n",
      "m**inal **mony**\" - a criminal amount of money.  This is because\n",
      " acrimony often arises from disputes over money or other material possessions.\n",
      "\n",
      "**Definition\n",
      "**: Acrimony is a feeling of bitterness or ill will, especially as shown in speech or conduct.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for word in vocab_words[0:5]:\n",
    "    print(f'Results for {word}:')\n",
    "    for r in palm_model.predict_streaming(\n",
    "        prompt = f'Describe the word {word} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "        max_output_tokens = 500\n",
    "    ):\n",
    "        print(r)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d0a3c-5dd2-49a9-ae76-afda540c62e9",
   "metadata": {},
   "source": [
    "## Asynchronous Use of APIs - Using Vertex AI Generative AI Models\n",
    "\n",
    "To request the definition for all words in the vocabularly list it will be beneficial to make request asynchronously - at the same time.  Some APIs have separate clients for asynchronous requests.  In the case of the PaLM model APIs there is actually a helpful asynchronous method provided `.predict_async()`.\n",
    "- [`.predict_async()` method](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models.TextGenerationModel#vertexai_language_models_TextGenerationModel_predict_async)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ac9af-d273-47ed-bb5a-9e7fc3139681",
   "metadata": {},
   "source": [
    "### What Exactly is Async?\n",
    "\n",
    "If we make a request with the async method the response is a [coroutine](https://docs.python.org/3/glossary.html#term-coroutine) object.  This means the method is already implemented with an `async def` statement which makes it [awaitable](https://docs.python.org/3/library/asyncio-task.html#awaitables)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937f2c5-b7bf-4c80-a35a-52d79a7e6e05",
   "metadata": {},
   "source": [
    "#### With PaLM:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d54ae36-d9f1-4280-a19d-def41bc8c3b4",
   "metadata": {},
   "source": [
    "The following cells show using the method with, and without, an await expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f94da73b-c7c6-45c3-968e-e6af6a0c103f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object _TextGenerationModel.predict_async at 0x7ff75556e730>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palm_model.predict_async(\n",
    "    prompt = f'Describe the word {vocab_words[0]} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "    max_output_tokens = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e59fb58-f2cc-417d-9e60-35f86a4b8a19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " **Mnemonic:** \n",
       "To remember the word \"abrogate,\" think of a \"broken gate.\" Just as a broken gate can no longer serve its purpose, something that is abrogated is no longer in effect.\n",
       "\n",
       "**Definition:**\n",
       "Abrogate means to repeal or annul a law, treaty, or agreement. It is a formal term often used in legal or political contexts to describe the official termination or cancellation of a previously established rule or arrangement."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await palm_model.predict_async(\n",
    "    prompt = f'Describe the word {vocab_words[0]} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "    max_output_tokens = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b54bc7-d671-4fe8-8dc1-49a7b6e516c5",
   "metadata": {},
   "source": [
    "#### With Gemini:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c59d5-96f1-4da8-ac5f-ace9ec58ca90",
   "metadata": {},
   "source": [
    "The following cells show using the method with, and without, an await expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bee3c26-970d-4b34-94d9-e7797a944a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object _GenerativeModel.generate_content_async at 0x7ff7543822d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_model.generate_content_async(\n",
    "    ['Describe the word', vocab_words[0], 'in a way that will make it easy to remember.']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3d32c20-b591-40fe-8ea5-f5b643915464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Abrogate** sounds like \"a broken gate.\" Just like a broken gate can\\'t keep something in or out, abrogate means to \"do away with\" or \"cancel.\"'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(await gemini_model.generate_content_async(\n",
    "    ['Describe the word', vocab_words[0], 'in a way that will make it easy to remember.']\n",
    ")).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc99c4-9b71-4551-bac8-eaf9803d2f86",
   "metadata": {},
   "source": [
    "### How To Use Async Concurrently\n",
    "\n",
    "The previous section showed that the `predict_async()` method returns a coroutine, which is an awaitable object.  When multiple coroutines are grouped together they can be awaited together - concurrently.\n",
    "\n",
    "To group the coroutines together use [asyncio.gather()](https://docs.python.org/3/library/asyncio-task.html#running-tasks-concurrently):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5579c38b-75b1-4552-bc88-6279c9c7a750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = asyncio.gather(*[\n",
    "    palm_model.predict_async(\n",
    "        prompt = f'Describe the word {word} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "        max_output_tokens = 500\n",
    "    ) for word in vocab_words[0:5]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "949d99f0-5b8c-41e3-bbe2-8447c1393ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asyncio.tasks._GatheringFuture"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a5b7ef-ec7a-48db-947d-423d632af8c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "To make the requests concurrent, `await` the coroutine grouping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fda8e0f5-f1e1-48db-8493-abb306c10420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = await asyncio.gather(*[\n",
    "    palm_model.predict_async(\n",
    "        prompt = f'Describe the word {word} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "        max_output_tokens = 500\n",
    "    ) for word in vocab_words[0:5]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b7c44b3-a500-44b9-a183-e00539ff044e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(responses), len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87a66b1a-0125-4154-af49-c0dc6b49da89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " **Mnemonic:** \n",
      "To remember the word \"abrogate,\" think of a \"broken gate.\" Just as a broken gate can no longer serve its purpose, something that is abrogated is no longer in effect.\n",
      "\n",
      "**Definition:**\n",
      "Abrogate means to repeal or annul a law, treaty, or agreement. It is a formal term often used in legal or political contexts to describe the official termination or cancellation of a previously established rule or arrangement.\n",
      "----------------------------------------------------------------------------------------------------\n",
      " **Mnemonic:** \n",
      "Imagine a thief quickly running away from the scene of a crime, leaving no trace behind. The word \"abscond\" sounds similar to \"absent,\" which is what the thief is from the scene.\n",
      "\n",
      "**Definition:** \n",
      "To leave suddenly and secretly, especially in order to escape from danger or avoid arrest.\n",
      "----------------------------------------------------------------------------------------------------\n",
      " **Mnemonic:** \n",
      "*Ac*cede sounds like \"**a** **see**d**.\"  Imagine planting a seed and watching it grow into a beautiful plant.  In the same way, when you accede to something, you are allowing it to grow and develop.\n",
      "\n",
      "**Definition:**\n",
      "To agree or consent to something, especially after some hesitation or reluctance.\n",
      "----------------------------------------------------------------------------------------------------\n",
      " **Mnemonic:** \n",
      "*Acqui*esce sounds like \"I *acqu*ire peace.\"\n",
      "\n",
      "**Definition:** \n",
      "To comply without protest; to agree or consent, usually reluctantly.\n",
      "----------------------------------------------------------------------------------------------------\n",
      " **Acrimony** can be remembered as \"**A** **cri**tic's **mo**od.\"\n",
      "\n",
      "**Definition**: bitterness or ill feeling, especially as shown in speech or conduct.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for response in responses:\n",
    "    print(response.text)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6104f7-3d52-4574-a911-6c8a25230fbb",
   "metadata": {},
   "source": [
    "## Managing Concurrency\n",
    "\n",
    "In some cases, doing all the tasks concurrently can work. Usually, there are limitations though. Waiting on a API to respond does not put a burden on the local compute so managing lots of requests may not be an issue on the client side.  It can still be helpful to put limits on concurrency for managing the requests.  A first step to limiting concurrency is using a tool like [asyncio.Semaphore](https://docs.python.org/3/library/asyncio-sync.html#semaphore) to managed a counter of current concurrent requests.\n",
    "\n",
    "The following builds a function that manages the full list of request and uses a semaphore to control the concurrency.  Think of this as the concurrency buffer limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a44af4bd-4885-4dc3-bc0e-29ef1767970a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def study_notes(instances, limit_concur_requests = 10):\n",
    "    limit = asyncio.Semaphore(limit_concur_requests)\n",
    "    results = [None] * len(instances)\n",
    "    \n",
    "    # make requests\n",
    "    async def make_request(p):\n",
    "        async with limit:\n",
    "            if limit.locked():\n",
    "                await asyncio.sleep(.01)\n",
    "            result = await palm_model.predict_async(\n",
    "                                prompt = f'Describe the word {instances[p]} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "                                max_output_tokens = 500\n",
    "                            )\n",
    "        results[p] = (instances[p], result.text)\n",
    "        \n",
    "    # manage tasks\n",
    "    tasks = [asyncio.create_task(make_request(p)) for p in range(len(instances))]\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd1fbbd2-6791-4e55-bbd9-51de77d51658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = await study_notes(vocab_words[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa073246-055a-4d39-ab00-2fb724bd8202",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, tuple, 20)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(responses), type(responses[0]), len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "794c12e3-2ded-406e-b8e9-de9ec06dbb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approbation\n",
      " **Mnemonic:** Think of \"approbation\" as \"approval with a pat on the back.\"\n",
      "\n",
      "**Definition:** Approbation is the expression of approval or praise, often accompanied by a sense of admiration or respect. It is a positive evaluation or endorsement of someone or something, typically given for their actions, achievements, or qualities. Approbation can be conveyed through words, gestures, or actions that demonstrate appreciation, support, or encouragement.\n"
     ]
    }
   ],
   "source": [
    "print(responses[-1][0])\n",
    "print(responses[-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a66a70-f3f7-41fd-ac0b-13623c324d9f",
   "metadata": {},
   "source": [
    "## Managing Concurrency - With Limits\n",
    "\n",
    "Just managing the concurrency may not be enough.  In cases where API have limits the total requests need to stay under these limits to prevent errors. In the case of this example, the PaLM model is limited by request per minute.  The default per project is 60 request per minute for the model used here ('text-bison@002').  See [Quotas and limits](https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai).\n",
    "\n",
    "The following modifies the previous function to also incorporate a time based limit for requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa11dc3c-94b5-4ab4-924e-b50f7c9d1e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def study_notes(instances, limit_concur_requests = 10, limit_per_minute = 60):\n",
    "    limit = asyncio.Semaphore(limit_concur_requests)\n",
    "    results = [None] * len(instances)\n",
    "    \n",
    "    # make requests\n",
    "    async def make_request(p):\n",
    "        \n",
    "        # pause for time based limit\n",
    "        if p >= limit_per_minute:\n",
    "            await asyncio.sleep(60 * (p // limit_per_minute))\n",
    "        \n",
    "        async with limit:\n",
    "            if limit.locked():\n",
    "                await asyncio.sleep(.01)\n",
    "            result = await palm_model.predict_async(\n",
    "                                prompt = f'Describe the word {instances[p]} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "                                max_output_tokens = 500\n",
    "                            )\n",
    "        results[p] = (instances[p], result.text)\n",
    "        \n",
    "    # manage tasks\n",
    "    tasks = [asyncio.create_task(make_request(p)) for p in range(len(instances))]\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5cb0c5-4032-4338-b27e-05d4be1fa7e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Try the function under the limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ceec214-b836-4ce1-a2ff-d84360661c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = await study_notes(vocab_words[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48e5c54b-63fa-4ba9-b9de-d2a84c43504b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 20)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(responses), len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a1d74be-79c6-4d2d-8897-8939f7b3651f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approbation\n",
      " **Mnemonic:** Think of \"approbation\" as \"approval with a pat on the back.\"\n",
      "\n",
      "**Definition:** Approbation is the expression of approval or praise, often accompanied by a sense of admiration or respect. It is a positive evaluation or endorsement of someone or something, typically given for their actions, achievements, or qualities. Approbation can be conveyed through words, gestures, or actions that demonstrate appreciation, support, or encouragement.\n"
     ]
    }
   ],
   "source": [
    "print(responses[-1][0])\n",
    "print(responses[-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef42f0-507e-49ff-a90f-5bbe03ff8b52",
   "metadata": {
    "tags": []
   },
   "source": [
    "Try the function just over the limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd2df1bd-bdb6-4169-8afd-9bc91bbca888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wait a minute for the qouta to clear - assumes no other activity in the project\n",
    "await asyncio.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08559b45-6ee0-45bf-9b31-3f57568fbde7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = await study_notes(vocab_words[0:65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22ceb0ca-85c2-4f76-bc36-d069991a323f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 65)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(responses), len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9e8651a-ded5-4f34-b005-8866b50435ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centrifugal\n",
      " **Mnemonic:** Think of a \"centrifuge,\" which is a machine that uses centrifugal force to separate materials. The word \"centrifugal\" contains the root word \"center,\" which is related to the idea of moving away from the center.\n",
      "\n",
      "**Definition:** Centrifugal refers to the force or tendency of an object to move away from the center of rotation or curvature. It is the opposite of centripetal force, which pulls objects towards the center.\n"
     ]
    }
   ],
   "source": [
    "print(responses[-1][0])\n",
    "print(responses[-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f0274f-8816-468a-b1bf-ec53cddff3ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "Try the function at triple the limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0627dee1-4caa-45ab-92b4-cf950a54a6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wait a minute for the qouta to clear - assumes no other activity in the project\n",
    "await asyncio.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdea97d8-3777-4d80-a6fa-f8ce233a743d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = await study_notes(vocab_words[0:180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b51bbd9-5e4a-4cfd-9bce-92e14c8ab76c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 180)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(responses), len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea3489db-6012-45bc-b4c5-dfbcdc1648ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esoteric\n",
      " **Mnemonic:** Esoteric sounds like \"secret.\"\n",
      "\n",
      "**Definition:** Esoteric means difficult to understand or know; obscure.\n"
     ]
    }
   ],
   "source": [
    "print(responses[-1][0])\n",
    "print(responses[-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c656a9-7678-4591-b73e-a9e4217a922f",
   "metadata": {},
   "source": [
    "## Managing Concurrency - With Limits And Error Handling\n",
    "\n",
    "Sometimes handling concurrency and limits is still not enough.  For example, in a shared enviornment it may not be possible to know how many other applications are making requesst in the same time frame.  In some cases clients have retry methods built in.  In other cases errors are returned and the calling application has to handle them.\n",
    "\n",
    "The following with futher modify the function to handle error responses by retrying and increasing time increment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e99c3f-04f7-4461-a841-b226aa8feca1",
   "metadata": {},
   "source": [
    "First, force an error by exceeding the limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79696e31-e84f-4aba-ac17-eccb5184ebe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResourceExhausted was raised: 429 Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: text-bison. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # setting the limit_per_minute to 80, higher than the actual limit of 60\n",
    "    responses = await study_notes(vocab_words[0:80], limit_per_minute = 80)\n",
    "except Exception as err:\n",
    "    print(f\"{type(err).__name__} was raised: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb5dbd5-e85b-471b-b674-8acdfc56714c",
   "metadata": {},
   "source": [
    "Now, Modify the function to capture the error and retry with incrementing wait times.  The method used below does two things:\n",
    "- sets a limit on the retries, 20 in this case\n",
    "- increments the wait time for each retry, exponential backoff in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b58bb0d7-cedf-4d1c-8aef-80637acf3ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def study_notes(instances, limit_concur_requests = 10, limit_per_minute = 60):\n",
    "    limit = asyncio.Semaphore(limit_concur_requests)\n",
    "    results = [None] * len(instances)\n",
    "    \n",
    "    # make requests\n",
    "    async def make_request(p):\n",
    "        \n",
    "        # pause for time based limit\n",
    "        if p >= limit_per_minute:\n",
    "            await asyncio.sleep(60 * (p // limit_per_minute))\n",
    "        \n",
    "        async with limit:\n",
    "            if limit.locked():\n",
    "                await asyncio.sleep(.01)\n",
    "            ########## ERROR HANDLING ##################################\n",
    "            fail_count = 0\n",
    "            while fail_count <= 20:\n",
    "                try:\n",
    "                    result = await palm_model.predict_async(\n",
    "                                        prompt = f'Describe the word {instances[p]} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "                                        max_output_tokens = 500\n",
    "                                    )\n",
    "                    if fail_count > 0:\n",
    "                        print(f'Item {p} succeed after fail count = {fail_count}')\n",
    "                    break\n",
    "                except:\n",
    "                    fail_count += 1\n",
    "                    print(f'Item {p} failed: current fail count = {fail_count}')\n",
    "                    await asyncio.sleep(2^(min(fail_count, 6) - 1))\n",
    "            ############################################################\n",
    "        results[p] = (instances[p], result.text)\n",
    "        \n",
    "    # manage tasks\n",
    "    tasks = [asyncio.create_task(make_request(p)) for p in range(len(instances))]\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f579a5f-a97d-4e63-904b-74316aab9f26",
   "metadata": {},
   "source": [
    "Try 200 words with the correct limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40394e47-ce7a-4660-955f-9f07caca2998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wait a minute for the qouta to clear - assumes no other activity in the project\n",
    "await asyncio.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4b73286-3617-450a-8bad-104008cdd63c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 124 failed: current fail count = 1\n",
      "Item 125 failed: current fail count = 1\n",
      "Item 122 failed: current fail count = 1\n",
      "Item 132 failed: current fail count = 1\n",
      "Item 133 failed: current fail count = 1\n",
      "Item 125 succeed after fail count = 1\n",
      "Item 122 succeed after fail count = 1\n",
      "Item 124 succeed after fail count = 1\n",
      "Item 133 succeed after fail count = 1\n",
      "Item 132 succeed after fail count = 1\n"
     ]
    }
   ],
   "source": [
    "responses = await study_notes(vocab_words[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7bc2d06-cc7f-41d7-a64d-b89744f61d73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 200)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(responses), len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f599d83e-9323-4bcc-8286-ac59991f7ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "felonious\n",
      " **Felonious**\n",
      "\n",
      "**Mnemonic:** A felonious act is a serious crime, like a felony.\n",
      "\n",
      "**Definition:** Relating to or constituting a felony.\n"
     ]
    }
   ],
   "source": [
    "print(responses[-1][0])\n",
    "print(responses[-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27781bf-2aba-4a0f-89b8-f7e23c2487b9",
   "metadata": {},
   "source": [
    "Now, try 200 words but force errors by setting the limit higher than the actual (60):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd2d2633-c308-4166-900c-84ccc707083e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wait a minute for the qouta to clear - assumes no other activity in the project\n",
    "await asyncio.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a653644-6f90-41d2-8ce2-eaa42df4cdf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 72 failed: current fail count = 1\n",
      "Item 73 failed: current fail count = 1\n",
      "Item 74 failed: current fail count = 1\n",
      "Item 76 failed: current fail count = 1\n",
      "Item 78 failed: current fail count = 1\n",
      "Item 79 failed: current fail count = 1\n",
      "Item 72 failed: current fail count = 2\n",
      "Item 73 failed: current fail count = 2\n",
      "Item 74 failed: current fail count = 2\n",
      "Item 76 failed: current fail count = 2\n",
      "Item 78 failed: current fail count = 2\n",
      "Item 79 failed: current fail count = 2\n",
      "Item 72 failed: current fail count = 3\n",
      "Item 72 failed: current fail count = 4\n",
      "Item 73 failed: current fail count = 3\n",
      "Item 73 failed: current fail count = 4\n",
      "Item 74 failed: current fail count = 3\n",
      "Item 74 failed: current fail count = 4\n",
      "Item 76 failed: current fail count = 3\n",
      "Item 76 failed: current fail count = 4\n",
      "Item 78 failed: current fail count = 3\n",
      "Item 78 failed: current fail count = 4\n",
      "Item 79 failed: current fail count = 3\n",
      "Item 79 failed: current fail count = 4\n",
      "Item 72 failed: current fail count = 5\n",
      "Item 73 failed: current fail count = 5\n",
      "Item 74 failed: current fail count = 5\n",
      "Item 76 failed: current fail count = 5\n",
      "Item 78 failed: current fail count = 5\n",
      "Item 79 failed: current fail count = 5\n",
      "Item 72 failed: current fail count = 6\n",
      "Item 73 failed: current fail count = 6\n",
      "Item 74 failed: current fail count = 6\n",
      "Item 76 failed: current fail count = 6\n",
      "Item 78 failed: current fail count = 6\n",
      "Item 79 failed: current fail count = 6\n",
      "Item 72 failed: current fail count = 7\n",
      "Item 73 failed: current fail count = 7\n",
      "Item 74 failed: current fail count = 7\n",
      "Item 76 failed: current fail count = 7\n",
      "Item 78 failed: current fail count = 7\n",
      "Item 79 failed: current fail count = 7\n",
      "Item 72 failed: current fail count = 8\n",
      "Item 73 failed: current fail count = 8\n",
      "Item 74 failed: current fail count = 8\n",
      "Item 76 failed: current fail count = 8\n",
      "Item 78 failed: current fail count = 8\n",
      "Item 79 failed: current fail count = 8\n",
      "Item 72 failed: current fail count = 9\n",
      "Item 73 failed: current fail count = 9\n",
      "Item 74 failed: current fail count = 9\n",
      "Item 76 failed: current fail count = 9\n",
      "Item 78 failed: current fail count = 9\n",
      "Item 79 failed: current fail count = 9\n",
      "Item 72 failed: current fail count = 10\n",
      "Item 73 failed: current fail count = 10\n",
      "Item 74 failed: current fail count = 10\n",
      "Item 76 failed: current fail count = 10\n",
      "Item 79 succeed after fail count = 9\n",
      "Item 78 succeed after fail count = 9\n",
      "Item 72 succeed after fail count = 10\n",
      "Item 73 succeed after fail count = 10\n",
      "Item 74 succeed after fail count = 10\n",
      "Item 76 succeed after fail count = 10\n",
      "Item 134 failed: current fail count = 1\n",
      "Item 138 failed: current fail count = 1\n",
      "Item 139 failed: current fail count = 1\n",
      "Item 140 failed: current fail count = 1\n",
      "Item 142 failed: current fail count = 1\n",
      "Item 144 failed: current fail count = 1\n",
      "Item 145 failed: current fail count = 1\n",
      "Item 146 failed: current fail count = 1\n",
      "Item 147 failed: current fail count = 1\n",
      "Item 134 failed: current fail count = 2\n",
      "Item 148 failed: current fail count = 1\n",
      "Item 138 failed: current fail count = 2\n",
      "Item 139 failed: current fail count = 2\n",
      "Item 140 failed: current fail count = 2\n",
      "Item 142 failed: current fail count = 2\n",
      "Item 144 failed: current fail count = 2\n",
      "Item 145 failed: current fail count = 2\n",
      "Item 146 failed: current fail count = 2\n",
      "Item 147 failed: current fail count = 2\n",
      "Item 148 failed: current fail count = 2\n",
      "Item 134 failed: current fail count = 3\n",
      "Item 134 failed: current fail count = 4\n",
      "Item 138 failed: current fail count = 3\n",
      "Item 138 failed: current fail count = 4\n",
      "Item 139 failed: current fail count = 3\n",
      "Item 139 failed: current fail count = 4\n",
      "Item 140 failed: current fail count = 3\n",
      "Item 140 failed: current fail count = 4\n",
      "Item 142 failed: current fail count = 3\n",
      "Item 142 failed: current fail count = 4\n",
      "Item 144 failed: current fail count = 3\n",
      "Item 144 failed: current fail count = 4\n",
      "Item 145 failed: current fail count = 3\n",
      "Item 134 failed: current fail count = 5\n",
      "Item 145 failed: current fail count = 4\n",
      "Item 146 failed: current fail count = 3\n",
      "Item 146 failed: current fail count = 4\n",
      "Item 138 failed: current fail count = 5\n",
      "Item 147 failed: current fail count = 3\n",
      "Item 139 failed: current fail count = 5\n",
      "Item 147 failed: current fail count = 4\n",
      "Item 140 failed: current fail count = 5\n",
      "Item 142 failed: current fail count = 5\n",
      "Item 144 failed: current fail count = 5\n",
      "Item 148 failed: current fail count = 3\n",
      "Item 145 failed: current fail count = 5\n",
      "Item 148 failed: current fail count = 4\n",
      "Item 146 failed: current fail count = 5\n",
      "Item 147 failed: current fail count = 5\n",
      "Item 148 failed: current fail count = 5\n",
      "Item 134 failed: current fail count = 6\n",
      "Item 138 failed: current fail count = 6\n",
      "Item 139 failed: current fail count = 6\n",
      "Item 140 failed: current fail count = 6\n",
      "Item 142 failed: current fail count = 6\n",
      "Item 144 failed: current fail count = 6\n",
      "Item 145 failed: current fail count = 6\n",
      "Item 146 failed: current fail count = 6\n",
      "Item 147 failed: current fail count = 6\n",
      "Item 148 failed: current fail count = 6\n",
      "Item 134 failed: current fail count = 7\n",
      "Item 138 failed: current fail count = 7\n",
      "Item 139 failed: current fail count = 7\n",
      "Item 140 failed: current fail count = 7\n",
      "Item 142 failed: current fail count = 7\n",
      "Item 144 failed: current fail count = 7\n",
      "Item 145 failed: current fail count = 7\n",
      "Item 146 failed: current fail count = 7\n",
      "Item 147 failed: current fail count = 7\n",
      "Item 148 failed: current fail count = 7\n",
      "Item 134 failed: current fail count = 8\n",
      "Item 138 failed: current fail count = 8\n",
      "Item 139 failed: current fail count = 8\n",
      "Item 140 failed: current fail count = 8\n",
      "Item 142 failed: current fail count = 8\n",
      "Item 144 failed: current fail count = 8\n",
      "Item 145 failed: current fail count = 8\n",
      "Item 146 failed: current fail count = 8\n",
      "Item 147 failed: current fail count = 8\n",
      "Item 148 failed: current fail count = 8\n",
      "Item 134 failed: current fail count = 9\n",
      "Item 138 failed: current fail count = 9\n",
      "Item 139 failed: current fail count = 9\n",
      "Item 140 failed: current fail count = 9\n",
      "Item 142 failed: current fail count = 9\n",
      "Item 144 failed: current fail count = 9\n",
      "Item 145 failed: current fail count = 9\n",
      "Item 146 failed: current fail count = 9\n",
      "Item 147 failed: current fail count = 9\n",
      "Item 148 failed: current fail count = 9\n",
      "Item 134 succeed after fail count = 9\n",
      "Item 140 succeed after fail count = 9\n",
      "Item 138 succeed after fail count = 9\n",
      "Item 142 succeed after fail count = 9\n",
      "Item 145 succeed after fail count = 9\n",
      "Item 146 succeed after fail count = 9\n",
      "Item 144 succeed after fail count = 9\n",
      "Item 139 succeed after fail count = 9\n",
      "Item 148 succeed after fail count = 9\n",
      "Item 147 succeed after fail count = 9\n"
     ]
    }
   ],
   "source": [
    "# setting the limit_per_minute to 80, higher than the actual limit of 60\n",
    "responses = await study_notes(vocab_words[0:200], limit_per_minute = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b2abe8b-74d9-48b7-96ba-7d31ad2b7162",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 200)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(responses), len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "914d0f11-b282-470a-8597-29da9afe4568",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "felonious\n",
      " **Felonious**\n",
      "\n",
      "**Mnemonic:** A felonious act is a serious crime, like a felony.\n",
      "\n",
      "**Definition:** Relating to or constituting a felony.\n"
     ]
    }
   ],
   "source": [
    "print(responses[-1][0])\n",
    "print(responses[-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4faeb2f-9a70-46d3-a21c-b1ef40fc5ef6",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Managing Concurrency - With Limits, Error Handling, and Regional Failover\n",
    "\n",
    "What if the max tries, `fail_count`, exceeds the threshold used?  This might be an indicator that the API is not responding.  A potential solution is switching to a different region.  The models provided by Vertex AI have [regional qouta](https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai#quotas_by_region_and_model) for each region they are available in - [location](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai). For instance, if you are working with PaLM models like this exampel from `us-central1` then it might be feasible to also consider `us-west1`, `us-west4`, or `us-east4`. \n",
    "\n",
    "The following builds upon the error handling and tries an alternative region once the `fail_count` is exceeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8d4bca0-1abd-421a-a622-6c9f115ec18e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wait a minute for the qouta to clear - assumes no other activity in the project\n",
    "await asyncio.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5799f0-a16e-4244-b32c-d622461a22a4",
   "metadata": {},
   "source": [
    "First, try the current model that is being used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9dd138a2-69da-4499-b2bd-6ff46007459b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " **Mnemonic:** Think of a \"riot\" of colors.\n",
       "\n",
       "**Definition:** A roit is a tumult or uproar, especially one involving a large number of people."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await palm_model.predict_async(\n",
    "    prompt = f'Describe the word {vocab_words[0]} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "    max_output_tokens = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639fa0bb-0770-491a-a613-23b95ff06862",
   "metadata": {
    "tags": []
   },
   "source": [
    "Make a backup connection to the same model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca344da4-1ef4-4059-a6d8-e3e5ea36af45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(location = 'us-east4')\n",
    "palm_model2 = vertexai.language_models.TextGenerationModel.from_pretrained(\"text-bison@002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f816494-d89c-4c6e-83c0-a8f00853d7b4",
   "metadata": {},
   "source": [
    "Now, try the backup model connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bdc0eb01-02fd-42b6-9b71-b8f2386151b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " **Mnemonic:** Think of a \"riot\" of colors.\n",
       "\n",
       "**Definition:** A roit is a tumult or uproar, especially one involving a large number of people and typically characterized by violence and destruction."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await palm_model2.predict_async(\n",
    "    prompt = f'Describe the word {vocab_words[0]} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "    max_output_tokens = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4445288-f258-4a92-ab4f-8de39a98fa1d",
   "metadata": {},
   "source": [
    "What happens if trying to connect to model in unsupported location?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d85dfc71-4226-41e0-90d2-220dfe945ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NotFound was raised: 404 Publisher Model `publishers/google/models/text-bison@002` is not found.\n"
     ]
    }
   ],
   "source": [
    "vertexai.init(location = 'us-east1')\n",
    "try:\n",
    "    palm_model2 = vertexai.language_models.TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "except Exception as err:\n",
    "    print(f\"{type(err).__name__} was raised: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565b9295-c924-4cb8-a280-45ca3bd1390c",
   "metadata": {},
   "source": [
    "Can the primary model connection still be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a383402f-d316-47f5-bf06-735e2e86ebe9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " **Mnemonic:** Think of a \"riot\" of colors.\n",
       "\n",
       "**Definition:** A roit is a tumult or uproar, especially one involving a large number of people."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await palm_model.predict_async(\n",
    "    prompt = f'Describe the word {vocab_words[0]} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "    max_output_tokens = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0438c0c5-faa6-469a-ae5e-33e5b18c6930",
   "metadata": {},
   "source": [
    "Now, officially set the backup to `us-east4` for use in error handling function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "830f2d13-d925-4171-a3a7-62d774af12c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(location = 'us-east4')\n",
    "palm_model2 = vertexai.language_models.TextGenerationModel.from_pretrained(\"text-bison@002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204db60b-c688-417d-b0c9-2cdcd98a13d1",
   "metadata": {},
   "source": [
    "Modify the function to try the backup model (location) after `fail_count >= region_check`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ecb0a9ec-74ee-4daa-b8fe-e915573cc3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def study_notes(instances, limit_concur_requests = 10, limit_per_minute = 60):\n",
    "    limit = asyncio.Semaphore(limit_concur_requests)\n",
    "    results = [None] * len(instances)\n",
    "    \n",
    "    # make requests\n",
    "    async def make_request(p):\n",
    "        \n",
    "        # pause for time based limit\n",
    "        if p >= limit_per_minute:\n",
    "            await asyncio.sleep(60 * (p // limit_per_minute))\n",
    "        \n",
    "        async with limit:\n",
    "            if limit.locked():\n",
    "                await asyncio.sleep(.01)\n",
    "            ########## ERROR HANDLING ##################################\n",
    "            fail_count = 0\n",
    "            region_check = 3\n",
    "            while fail_count <= 20:\n",
    "                try:\n",
    "                    result = await palm_model.predict_async(\n",
    "                                        prompt = f'Describe the word {instances[p]} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "                                        max_output_tokens = 500\n",
    "                                    )\n",
    "                    if fail_count > 0:\n",
    "                        print(f'Item {p} succeed after fail count = {fail_count}')\n",
    "                    break\n",
    "                except:\n",
    "                    fail_count += 1\n",
    "                    print(f'Item {p} failed: current fail count = {fail_count}')\n",
    "                    ########## REGIONAL Failover check ########################################\n",
    "                    if fail_count >= region_check:\n",
    "                        try:\n",
    "                            result = await palm_model2.predict_async(\n",
    "                                                prompt = f'Describe the word {instances[p]} in a way that will make it easy to remember.  Then, provide a definition of the word.',\n",
    "                                                max_output_tokens = 500\n",
    "                                            )\n",
    "                            if fail_count > 0:\n",
    "                                print(f'Item {p} succeed after fail count = {fail_count} by trying a backup region.')\n",
    "                            break\n",
    "                        except:\n",
    "                            print(f'Item {p} failed: current fail count = {fail_count}. This was a Regional Failover check.')\n",
    "                    ###########################################################################\n",
    "                    await asyncio.sleep(2^(min(fail_count, 6) - 1))\n",
    "            ############################################################\n",
    "        results[p] = (instances[p], result.text)\n",
    "        \n",
    "    # manage tasks\n",
    "    tasks = [asyncio.create_task(make_request(p)) for p in range(len(instances))]\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c91ed-1c34-4785-96d0-99a5f259ee75",
   "metadata": {},
   "source": [
    "Now, try 200 words but force errors by setting the limit higher than the actual (60):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4aa09899-11f7-4ca1-8873-d5594097784c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wait a minute for the qouta to clear - assumes no other activity in the project\n",
    "await asyncio.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb171512-dd48-40d8-8b02-66bca03fd334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 71 failed: current fail count = 1\n",
      "Item 72 failed: current fail count = 1\n",
      "Item 75 failed: current fail count = 1\n",
      "Item 77 failed: current fail count = 1\n",
      "Item 78 failed: current fail count = 1\n",
      "Item 79 failed: current fail count = 1\n",
      "Item 71 failed: current fail count = 2\n",
      "Item 72 failed: current fail count = 2\n",
      "Item 75 failed: current fail count = 2\n",
      "Item 77 failed: current fail count = 2\n",
      "Item 78 failed: current fail count = 2\n",
      "Item 79 failed: current fail count = 2\n",
      "Item 72 failed: current fail count = 3\n",
      "Item 75 failed: current fail count = 3\n",
      "Item 77 failed: current fail count = 3\n",
      "Item 71 succeed after fail count = 2\n",
      "Item 72 succeed after fail count = 3 by trying a backup region.\n",
      "Item 77 succeed after fail count = 3 by trying a backup region.\n",
      "Item 79 succeed after fail count = 2\n",
      "Item 78 succeed after fail count = 2\n",
      "Item 75 succeed after fail count = 3 by trying a backup region.\n",
      "Item 137 failed: current fail count = 1\n",
      "Item 138 failed: current fail count = 1\n",
      "Item 145 failed: current fail count = 1\n",
      "Item 146 failed: current fail count = 1\n",
      "Item 147 failed: current fail count = 1\n",
      "Item 148 failed: current fail count = 1\n",
      "Item 150 failed: current fail count = 1\n",
      "Item 151 failed: current fail count = 1\n",
      "Item 152 failed: current fail count = 1\n",
      "Item 153 failed: current fail count = 1\n",
      "Item 137 failed: current fail count = 2\n",
      "Item 138 failed: current fail count = 2\n",
      "Item 145 failed: current fail count = 2\n",
      "Item 146 failed: current fail count = 2\n",
      "Item 147 failed: current fail count = 2\n",
      "Item 148 failed: current fail count = 2\n",
      "Item 150 failed: current fail count = 2\n",
      "Item 151 failed: current fail count = 2\n",
      "Item 152 failed: current fail count = 2\n",
      "Item 153 failed: current fail count = 2\n",
      "Item 137 failed: current fail count = 3\n",
      "Item 138 failed: current fail count = 3\n",
      "Item 137 succeed after fail count = 3 by trying a backup region.\n",
      "Item 146 succeed after fail count = 2\n",
      "Item 138 succeed after fail count = 3 by trying a backup region.\n",
      "Item 145 succeed after fail count = 2\n",
      "Item 150 failed: current fail count = 3\n",
      "Item 148 succeed after fail count = 2\n",
      "Item 151 succeed after fail count = 2\n",
      "Item 147 succeed after fail count = 2\n",
      "Item 152 succeed after fail count = 2\n",
      "Item 150 succeed after fail count = 3 by trying a backup region.\n",
      "Item 153 succeed after fail count = 2\n"
     ]
    }
   ],
   "source": [
    "# setting the limit_per_minute to 80, higher than the actual limit of 60\n",
    "responses = await study_notes(vocab_words[0:200], limit_per_minute = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6574f7a1-a023-4819-9ce7-58596e18ece0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 200)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(responses), len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53213d2f-6309-460b-9d7f-96a587d66c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "felonious\n",
      " **Felonious**\n",
      "\n",
      "**Mnemonic:** A felonious act is a serious crime, like a felony.\n",
      "\n",
      "**Definition:** Relating to or constituting a felony.\n"
     ]
    }
   ],
   "source": [
    "print(responses[-1][0])\n",
    "print(responses[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb148d-2973-41a8-8fb6-20de924d754b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
