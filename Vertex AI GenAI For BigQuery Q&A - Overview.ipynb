{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3280a90a-c51c-4de1-9411-5f6fa60c8a4f",
   "metadata": {},
   "source": [
    "![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2FApplied+GenAI&dt=Vertex+AI+GenAI+For+BigQuery+Q%26A+-+Overview.ipynb)\n",
    "\n",
    "# Answering Questions Using BigQuery Tables As Context\n",
    "\n",
    "Ask Question of a table in BigQuery.  How?  First translated the quesiton to SQL and extract results from the BigQuery Table.  Then provide the results as context with the orignal question to an LLM for answering.\n",
    "\n",
    "The workflow:\n",
    "- Setup Enviornment\n",
    "- Setup access to LLMs: Test and Code\n",
    "- Retrieve Table Schemas using BigQuery Information Schema\n",
    "- Translate Question to Code (SQL) with context of table schemas\n",
    "- Ask an LLM to answer the question with context of results from running the generated SQL\n",
    "- Ask more question!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547187ca-ed00-4174-9262-ef8deac19bc9",
   "metadata": {
    "id": "R0Q3cgMcshvL"
   },
   "source": [
    "---\n",
    "## Overview\n",
    "\n",
    "<p><center>\n",
    "    <img alt=\"Overview Chart\" src=\"../architectures/notebooks/applied/genai/bq_qa.png\" width=\"55%\">\n",
    "</center><p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2bded-23ce-4761-8df1-562240f17be6",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Vertex%20AI%20GenAI%20For%20BigQuery%20Q&A%20-%20Overview.ipynb) and run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0cee4a-d31e-4511-a74d-4c890d9bcca1",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10adc2fa-c1ed-4368-8ab7-3216e3df7451",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638aeb5-d4ae-4234-8a4a-f162eeb130e7",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment.  Also, the APIs for Cloud Speech-To-Text and Cloud Text-To-Speech need to be enabled (if not already enabled)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553ea40-3ab9-47aa-a992-bd0ad83e4211",
   "metadata": {},
   "source": [
    "### Installs (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d64660-8af0-4734-8cb4-2403364f5d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "install = False\n",
    "try: import google.cloud.aiplatform\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-aiplatform (VERTEX AI), ... commencing')\n",
    "    !pip install google-cloud-aiplatform -U -q\n",
    "    install = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31f72b-cf98-4c91-8ef6-58f181fc11a1",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc6de4a-610a-4498-885d-111a43ac5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd823b-b93c-4571-b80e-8ee70de32f0a",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702c4747-d1ed-4901-b65f-6875a4019f89",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65fb598d-a230-44e1-b4fb-5bc53413a145",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e3a060-251a-463a-aa76-77f5ddf2aebe",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku"
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'bq-citibikes'\n",
    "SERIES = 'applied-genai'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff5fa0-3753-41b0-97ec-e23127faebd9",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32af0aab-3889-43c1-b34d-29bb13c0ef8f",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 17:42:42.746667: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import vertexai.language_models\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f461c-7f9c-4e4b-83aa-aff2e5593c9c",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "659a377b-ed33-408d-8af7-a4b398758612",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce"
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# bigquery client\n",
    "bq = bigquery.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03013d83-8d11-43ad-82e7-6651264c63d5",
   "metadata": {},
   "source": [
    "---\n",
    "## Goal\n",
    "\n",
    "New York City has [Citibike](https://citibikenyc.com/) stations where you can rent a bicycle by the ride, the day, or subscribe monthly/annually.  There is a sample of the usage of citibike stations in BigQuery public datasets.  We would like to answer possible questions in natural langauge using this data as the source.\n",
    "\n",
    "A possible quesiton is: Which Citibike station has the most rental during July 2015?\n",
    "\n",
    "The appoach used here is ask an LLM to answer the question.  The approach has multiple steps:\n",
    "1. Ask a code generation LLM to write a SQL query that retrives the relevant information to the question from the tables - the context\n",
    "2. Run the query generated in 1\n",
    "3. Ask a text generation LLM to answer the question and give it a context to help accurately answer the question - the result of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4472aab-2adc-4dcb-8207-31121a24a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which station had most rentals (longest total duration) during July 2015?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149f48d8-5ccf-46e7-89d4-8b6f38bc1513",
   "metadata": {
    "id": "PF_zXB00TMao"
   },
   "source": [
    "---\n",
    "## Vertex LLM Setup\n",
    "\n",
    "- CodeGenerationgModel [Guide](https://cloud.google.com/vertex-ai/docs/generative-ai/code/code-generation-prompts)\n",
    "    - CodeGenerationModel [API](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models.CodeGenerationModel)\n",
    "- TextGenerationModel [Guide](https://cloud.google.com/vertex-ai/docs/generative-ai/text/test-text-prompts)\n",
    "    - TextGenerationModel [API](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.preview.language_models.TextGenerationModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d596bd-980c-4f44-ba59-225318094d9a",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1683726409314,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "dn2FH-pETUPf"
   },
   "outputs": [],
   "source": [
    "# create links to model: embedding api and text generation\n",
    "textgen_model = vertexai.language_models.TextGenerationModel.from_pretrained('text-bison')\n",
    "codegen_model = vertexai.language_models.CodeGenerationModel.from_pretrained('code-bison')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f4d2d3-4aab-4fc3-88a9-d602c6f1b5fd",
   "metadata": {
    "id": "qEITqYF1QNkP"
   },
   "source": [
    "Test test generation (llm) model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed9baa8c-c678-42d9-ab14-d2a8015a369c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1758,
     "status": "ok",
     "timestamp": 1683726411751,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "ippLc2_eYeQH",
    "outputId": "c09300ed-9e44-40a7-f3d0-f4a95515021c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " ```sql\n",
       "SELECT start_station_id,\n",
       "       SUM(duration_minutes) AS total_duration\n",
       "FROM bike_sharing_trips\n",
       "WHERE EXTRACT(MONTH FROM start_time) = 7\n",
       "  AND EXTRACT(YEAR FROM start_time) = 2015\n",
       "GROUP BY start_station_id\n",
       "ORDER BY total_duration DESC\n",
       "LIMIT 1;\n",
       "```"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textgen_model.predict(f\"Write a Google SQL query that answers the following question.\\nquestion: {question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8478341a-dff0-4525-a1e5-10c9d9368fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "```sql\n",
       "SELECT start_station_id,\n",
       "       SUM(duration_minutes) AS total_duration\n",
       "FROM bike_sharing_trips\n",
       "WHERE DATE BETWEEN '2015-07-01' AND '2015-07-31'\n",
       "GROUP BY start_station_id\n",
       "ORDER BY total_duration DESC\n",
       "LIMIT 1;\n",
       "```"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codegen_model.predict(f\"Write a Google SQL query that answers the following question.\\nquestion: {question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11062730-255b-437c-be82-f9ec22aaa781",
   "metadata": {},
   "source": [
    "These both write code but notice how it has to make assumptions about table names and column names.  The following section address how to guide the LLM to write runnable SQL with correct tables and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7acbf5-8538-4404-8c29-a83d7b68b0f1",
   "metadata": {},
   "source": [
    "---\n",
    "## The Problem\n",
    "Both LLMs write valid SQL queries.  However, notice that asking either LLM to write the query this way faces several issues:\n",
    "- The queries do not reference the correct tables\n",
    "- The column names are not the correct ones from the correct tables\n",
    "\n",
    "Basically, the generated SQL is a good starting point for a user to write a query that would retrieve the valid context for the users question.\n",
    "\n",
    "**How to get a fully executable SQL query from the LLM?**\n",
    "\n",
    "The following approach was created by iteratively refining text prompts and approaches for specific questions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40a597f-3cbe-4c9d-8955-6422f611fff2",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieve Table Schemas\n",
    "\n",
    "The context that will be provided to the LLM to help write the SQL query will be the related tables schema.  The BigQuery tables used for this experiment are BigQuery public dataset tables:\n",
    "- `bigquery-public-data.new_york.citibike_trips`\n",
    "- `bigquery-public-data.new_york.citibike_stations`\n",
    "\n",
    "To retrive the schemas for the tables the BigQuery [INFORMATION_SCHEMA](https://cloud.google.com/bigquery/docs/information-schema-intro) is used - specifically the [INFORMATION_SCHEMA.COLUMN_FIELD_PATHS](https://cloud.google.com/bigquery/docs/information-schema-column-field-paths) view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32c4fe65-47a7-4347-a420-52904fa8a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BQ_PROJECT = 'bigquery-public-data'\n",
    "BQ_DATASET = 'new_york'\n",
    "BQ_TABLES = ['citibike_trips', 'citibike_stations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "909fe317-e61d-4d2c-a35c-23255c678be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT *\n",
      "    FROM `bigquery-public-data.new_york.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
      "    WHERE table_name in (\"citibike_trips\",\"citibike_stations\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM `{BQ_PROJECT}.{BQ_DATASET}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "    WHERE table_name in ({','.join([f'\"{table}\"' for table in BQ_TABLES])})\n",
    "\"\"\"\n",
    "print(query)\n",
    "schema_columns = bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a5a58cd-4e06-4737-92c5-ad77ae76d05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_catalog</th>\n",
       "      <th>table_schema</th>\n",
       "      <th>table_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>field_path</th>\n",
       "      <th>data_type</th>\n",
       "      <th>description</th>\n",
       "      <th>collation_name</th>\n",
       "      <th>rounding_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>new_york</td>\n",
       "      <td>citibike_stations</td>\n",
       "      <td>station_id</td>\n",
       "      <td>station_id</td>\n",
       "      <td>STRING</td>\n",
       "      <td>Unique identifier of a station.</td>\n",
       "      <td>NULL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>new_york</td>\n",
       "      <td>citibike_stations</td>\n",
       "      <td>name</td>\n",
       "      <td>name</td>\n",
       "      <td>STRING</td>\n",
       "      <td>Public name of the station.</td>\n",
       "      <td>NULL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>new_york</td>\n",
       "      <td>citibike_stations</td>\n",
       "      <td>short_name</td>\n",
       "      <td>short_name</td>\n",
       "      <td>STRING</td>\n",
       "      <td>Short name or other type of identifier, as use...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>new_york</td>\n",
       "      <td>citibike_stations</td>\n",
       "      <td>latitude</td>\n",
       "      <td>latitude</td>\n",
       "      <td>FLOAT64</td>\n",
       "      <td>The latitude of station. The field value must ...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>new_york</td>\n",
       "      <td>citibike_stations</td>\n",
       "      <td>longitude</td>\n",
       "      <td>longitude</td>\n",
       "      <td>FLOAT64</td>\n",
       "      <td>The longitude of station. The field value must...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          table_catalog table_schema         table_name column_name  \\\n",
       "0  bigquery-public-data     new_york  citibike_stations  station_id   \n",
       "1  bigquery-public-data     new_york  citibike_stations        name   \n",
       "2  bigquery-public-data     new_york  citibike_stations  short_name   \n",
       "3  bigquery-public-data     new_york  citibike_stations    latitude   \n",
       "4  bigquery-public-data     new_york  citibike_stations   longitude   \n",
       "\n",
       "   field_path data_type                                        description  \\\n",
       "0  station_id    STRING                    Unique identifier of a station.   \n",
       "1        name    STRING                        Public name of the station.   \n",
       "2  short_name    STRING  Short name or other type of identifier, as use...   \n",
       "3    latitude   FLOAT64  The latitude of station. The field value must ...   \n",
       "4   longitude   FLOAT64  The longitude of station. The field value must...   \n",
       "\n",
       "  collation_name rounding_mode  \n",
       "0           NULL          None  \n",
       "1           NULL          None  \n",
       "2           NULL          None  \n",
       "3           NULL          None  \n",
       "4           NULL          None  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9bca640-fc80-4e7f-9662-2acc19c55cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema_columns.to_markdown(index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f57010-2472-463f-b5b6-38aada160895",
   "metadata": {},
   "source": [
    "---\n",
    "## Notes On Efficient Information Schema Retrieval\n",
    "\n",
    "In this example the entire schema is used as context.  But what happens when there are many table and many columns?  Eventually the size will exceed the input size of the LLM.  It is also possible to misguide the LLM in the creation of code by supply too much information - especially when on different topics.\n",
    "\n",
    "Using semantic retrieval with embeddings is a great solution in this situation:\n",
    "- create embeddings for all table descriptions\n",
    "- create embeddings for all column descriptions\n",
    "- create a vector database with indexes for tables and embeddings\n",
    "- When a new question comes in find the most applicable table(s) and columns:\n",
    "    - embed the questions\n",
    "    - do a vector search for matching table(s)\n",
    "    - do a vector search for matching columns on the already matched table(s)\n",
    "    - prepare a schema for just the matched tables and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ecd1b9-bbc4-4a95-827b-b801d133de4a",
   "metadata": {},
   "source": [
    "---\n",
    "## Code Generation LLM - With Context\n",
    "\n",
    "In this attempt, ask the code generation LLM to write valid SQL and also provide it context.  In this case the context is the schema of the tables that are relevant to Citibike rentals.\n",
    "\n",
    "Turning the table that represent the schema into context is done here by using a conversion to markdown.  This is an area where users can experiment with the format.  JSON, CSV, ....  I like markdown because it includes the column names a single time and is delimited by the header row notation of markdown!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "399617ce-f17e-4488-b13f-8cb3b1e3058e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which station had most rentals (longest total duration) during July 2015?\n"
     ]
    }
   ],
   "source": [
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c0c62f0-93dd-40f5-bb03-03f149d78472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT \n",
      "  start_station_name AS station_name,\n",
      "  SUM(tripduration) AS total_duration_minutes\n",
      "FROM bigquery-public-data.new_york.citibike_trips\n",
      "WHERE \n",
      "  EXTRACT(MONTH FROM starttime) = 7\n",
      "  AND EXTRACT(YEAR FROM starttime) = 2015\n",
      "GROUP BY 1\n",
      "ORDER BY 2 DESC\n",
      "LIMIT 1;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "context_prompt = f\"\"\"\n",
    "Write a Google SQL query for BigQuery that answers the following question while using the provided context to correctly refer to BigQuery tables and the needed column names.  When joining tables use coersion to ensure all join columns are the same data type. Output column names should include the units when applicable.  Tables should be refered to using a fully qualified name include project and dataset along with table name. \n",
    "question:\n",
    "{question}\n",
    "\n",
    "context:\n",
    "{schema_columns.to_markdown(index = False)}\n",
    "\"\"\"\n",
    "\n",
    "context_query = codegen_model.predict(context_prompt, max_output_tokens = 256)\n",
    "\n",
    "print(context_query.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef9e6f4b-b12d-4d90-b150-73abf52af20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(context_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8743db49-3ff4-4398-ac4a-4d6c4df57e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_response = bq.query(query = '\\n'.join(context_query.text.split('\\n')[1:-1])).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7f2a311-eef2-44e8-ae4c-98a0011e9cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>total_duration_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Central Park S &amp; 6 Ave</td>\n",
       "      <td>18055103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             station_name  total_duration_minutes\n",
       "0  Central Park S & 6 Ave                18055103"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566bfc1-2e5d-4d1b-9535-67a1722e7091",
   "metadata": {},
   "source": [
    "---\n",
    "## Answer The Question\n",
    "\n",
    "Now that a valid context has been retrieved from BigQuery it can be passed to a text generation LLM to answer the user questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1c54bd8-426c-4f5a-bf16-2e74cf52b40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Central Park S & 6 Ave\n"
     ]
    }
   ],
   "source": [
    "question_prompt = f\"\"\"\n",
    "Answer the following question using the provided context.  Note that the context is a tabular result returned from a BigQuery query.  Do not repeat the question or the context when responding.\n",
    "\n",
    "question:\n",
    "{question}\n",
    "context:\n",
    "{context_response.to_markdown(index = False)}\n",
    "\"\"\"\n",
    "\n",
    "question_response = textgen_model.predict(question_prompt)\n",
    "\n",
    "print(question_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b947ade0-57a4-47c7-98b3-677412954abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(question_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de864c1-c95c-4944-b871-3a2010d38ced",
   "metadata": {},
   "source": [
    "---\n",
    "## Put It All Together\n",
    "\n",
    "Ask a new question and try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dd52257-baa4-43d0-84c1-5dfaea18d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'What were the top five stations with most unique trips in July 2015?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73786cfa-7845-4372-b735-e933a22b1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_prompt = f\"\"\"\n",
    "Write a Google SQL query for BigQuery that answers the following question while using the provided context to correctly refer to BigQuery tables and the needed column names.  When joining tables use coersion to ensure all join columns are the same data type. Output column names should include the units when applicable.  Tables should be refered to using a fully qualified name include project and dataset along with table name. \n",
    "question:\n",
    "{question}\n",
    "\n",
    "context:\n",
    "\n",
    "{schema_columns.to_markdown(index = False)}\n",
    "\"\"\"\n",
    "\n",
    "context_query = codegen_model.predict(context_prompt, max_output_tokens = 256)\n",
    "\n",
    "context_response = bq.query(query = '\\n'.join(context_query.text.split('\\n')[1:-1])).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e66d2bb-bb63-4ee6-8347-ea8d3c56f494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| station_name          |   unique_trips |\n",
      "|:----------------------|---------------:|\n",
      "| 8 Ave & W 31 St       |           6004 |\n",
      "| Pershing Square North |           5468 |\n",
      "| West St & Chambers St |           5259 |\n",
      "| Lafayette St & E 8 St |           5144 |\n",
      "| E 17 St & Broadway    |           5116 |\n"
     ]
    }
   ],
   "source": [
    "print(context_response.to_markdown(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58fe980c-8edf-4356-99ee-214f5d54a975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 8 Ave & W 31 St (6004)\n",
      "2. Pershing Square North (5468)\n",
      "3. West St & Chambers St (5259)\n",
      "4. Lafayette St & E 8 St (5144)\n",
      "5. E 17 St & Broadway (5116)\n"
     ]
    }
   ],
   "source": [
    "question_prompt = f\"\"\"\n",
    "Answer the following question using the provided context.  Note that the context is a tabular result returned from a BigQuery query.  Do not repeat the question or the context when responding.\n",
    "\n",
    "question:\n",
    "{question}\n",
    "context:\n",
    "{context_response.to_markdown(index = False)}\n",
    "\"\"\"\n",
    "\n",
    "question_response = textgen_model.predict(question_prompt)\n",
    "\n",
    "print(question_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9935f-80b3-41fe-b372-2b83a9798031",
   "metadata": {},
   "source": [
    "---\n",
    "## All Together and More Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2326bbd0-41a7-478e-807e-67958e6a67db",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'What were the top five stations with most trips started in July 2015 near central park?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ac10690-7cdd-4274-a0d0-cee8caa45833",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_prompt = f\"\"\"\n",
    "Write a Google SQL query for BigQuery that answers the following question while using the provided context to correctly refer to BigQuery tables and the needed column names.  When joining tables use coersion to ensure all join columns are the same data type. Output column names should include the units when applicable.  Tables should be refered to using a fully qualified name include project and dataset along with table name. \n",
    "question:\n",
    "{question}\n",
    "\n",
    "context:\n",
    "\n",
    "{schema_columns.to_markdown(index = False)}\n",
    "\"\"\"\n",
    "\n",
    "context_query = codegen_model.predict(context_prompt, max_output_tokens = 256)\n",
    "\n",
    "context_response = bq.query(query = '\\n'.join(context_query.text.split('\\n')[1:-1])).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b99afbeb-8f97-4f63-9881-d85d2dd710fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "```sql\n",
       "SELECT\n",
       "  start_station_name AS station_name,\n",
       "  COUNT(*) AS num_trips\n",
       "FROM\n",
       "  bigquery-public-data.new_york.citibike_trips\n",
       "WHERE\n",
       "  EXTRACT(MONTH FROM starttime) = 7\n",
       "  AND EXTRACT(YEAR FROM starttime) = 2015\n",
       "  AND start_station_latitude BETWEEN 40.769 AND 40.784\n",
       "  AND start_station_longitude BETWEEN -73.984 AND -73.964\n",
       "GROUP BY\n",
       "  start_station_name\n",
       "ORDER BY\n",
       "  num_trips DESC\n",
       "LIMIT\n",
       "  5;\n",
       "```"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1b43b84-47b1-49fa-b024-0639b2557df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The top five stations with the most trips started in July 2015 near Central Park are:\n",
      "\n",
      "1. Broadway & W 60 St (8793 trips) - Central Park Zoo, Lincoln Center, Time Warner Center\n",
      "2. 5 Ave/59 St       (7602 trips) - Central Park Zoo, The Plaza Hotel, FAO Schwarz\n",
      "3. Columbus Circle   (6841 trips) - Central Park South, Museum of Modern Art, Time Warner Center\n",
      "4. 8 Ave/W 59 St     (6311 trips) - Central Park South, Lincoln Center, Hearst Tower\n",
      "5. 7 Ave/W 59 St     (5993 trips) - Central Park South, The Plaza Hotel, FAO Schwarz\n"
     ]
    }
   ],
   "source": [
    "question_prompt = f\"\"\"\n",
    "Answer the following question using the provided context.  Note that the context is a tabular result returned from a BigQuery query.  Do not repeat the question or the context when responding.\n",
    "\n",
    "Include popular points of interest near each listed station.\n",
    "\n",
    "question:\n",
    "{question}\n",
    "context:\n",
    "{context_response.to_markdown(index = False)}\n",
    "\"\"\"\n",
    "\n",
    "question_response = textgen_model.predict(question_prompt, max_output_tokens = 500)\n",
    "\n",
    "print(question_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82153358-d248-47eb-b8dd-0b5795b8ba89",
   "metadata": {},
   "source": [
    "---\n",
    "## When The Generated Query Fails...\n",
    "\n",
    "The following question leads to an error in the `context_query` execution.  This section covers a method of using a Code Chat LLM to iteratively fix the query based on the error details returned from the job execution in BigQuery.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2ebd4319-5ebd-48f0-85f6-50652d622955",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many trips were started on a weekend, in the afternoon, during 2015, by a regular rider, who is over the age of 60?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09ba99b9-f668-47b2-b8c6-bd8f83af91f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_prompt = f\"\"\"\n",
    "Write a Google SQL query for BigQuery that answers the following question while using the provided context to correctly refer to BigQuery tables and the needed column names.  When joining tables use coersion to ensure all join columns are the same data type. Output column names should include the units when applicable.  Tables should be refered to using a fully qualified name include project and dataset along with table name. \n",
    "question:\n",
    "{question}\n",
    "\n",
    "context:\n",
    "\n",
    "{schema_columns.to_markdown(index = False)}\n",
    "\"\"\"\n",
    "\n",
    "context_query = codegen_model.predict(context_prompt, max_output_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28dc512d-bcfd-425b-bb1a-0c57fef354fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "```sql\n",
       "SELECT COUNT(*) AS num_trips\n",
       "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
       "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
       "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
       "WHERE \n",
       "  EXTRACT(WEEKDAY FROM starttime) IN (0, 6)\n",
       "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
       "  AND EXTRACT(YEAR FROM starttime) = 2015\n",
       "  AND usertype = 'Subscriber'\n",
       "  AND birth_year < 1955;\n",
       "```"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "645c885b-da6b-464b-a2b5-168266e90fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment an run this query - it will fail - due to WEEKDAY is not a valid date part - 10/17/2023\n",
    "#context_response = bq.query(query = '\\n'.join(context_query.text.split('\\n')[1:-1])).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f8433f-d5b4-41ee-a824-1844be59be23",
   "metadata": {},
   "source": [
    "```\n",
    "---------------------------------------------------------------------------\n",
    "BadRequest                                Traceback (most recent call last)\n",
    "Cell In[325], line 1\n",
    "----> 1 context_response = bq.query(query = '\\n'.join(context_query.text.split('\\n')[1:-1])).to_dataframe()\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1799, in QueryJob.to_dataframe(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype)\n",
    "   1633 def to_dataframe(\n",
    "   1634     self,\n",
    "   1635     bqstorage_client: Optional[\"bigquery_storage.BigQueryReadClient\"] = None,\n",
    "   (...)\n",
    "   1648     timestamp_dtype: Union[Any, None] = None,\n",
    "   1649 ) -> \"pandas.DataFrame\":\n",
    "   1650     \"\"\"Return a pandas DataFrame from a QueryJob\n",
    "   1651 \n",
    "   1652     Args:\n",
    "   (...)\n",
    "   1797             :mod:`shapely` library cannot be imported.\n",
    "   1798     \"\"\"\n",
    "-> 1799     query_result = wait_for_query(self, progress_bar_type, max_results=max_results)\n",
    "   1800     return query_result.to_dataframe(\n",
    "   1801         bqstorage_client=bqstorage_client,\n",
    "   1802         dtypes=dtypes,\n",
    "   (...)\n",
    "   1813         timestamp_dtype=timestamp_dtype,\n",
    "   1814     )\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_tqdm_helpers.py:104, in wait_for_query(query_job, progress_bar_type, max_results)\n",
    "    100 progress_bar = get_progress_bar(\n",
    "    101     progress_bar_type, \"Query is running\", default_total, \"query\"\n",
    "    102 )\n",
    "    103 if progress_bar is None:\n",
    "--> 104     return query_job.result(max_results=max_results)\n",
    "    106 i = 0\n",
    "    107 while True:\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1520, in QueryJob.result(self, page_size, max_results, retry, timeout, start_index, job_retry)\n",
    "   1517     if retry_do_query is not None and job_retry is not None:\n",
    "   1518         do_get_result = job_retry(do_get_result)\n",
    "-> 1520     do_get_result()\n",
    "   1522 except exceptions.GoogleAPICallError as exc:\n",
    "   1523     exc.message = _EXCEPTION_FOOTER_TEMPLATE.format(\n",
    "   1524         message=exc.message, location=self.location, job_id=self.job_id\n",
    "   1525     )\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:349, in Retry.__call__.<locals>.retry_wrapped_func(*args, **kwargs)\n",
    "    345 target = functools.partial(func, *args, **kwargs)\n",
    "    346 sleep_generator = exponential_sleep_generator(\n",
    "    347     self._initial, self._maximum, multiplier=self._multiplier\n",
    "    348 )\n",
    "--> 349 return retry_target(\n",
    "    350     target,\n",
    "    351     self._predicate,\n",
    "    352     sleep_generator,\n",
    "    353     self._timeout,\n",
    "    354     on_error=on_error,\n",
    "    355 )\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:191, in retry_target(target, predicate, sleep_generator, timeout, on_error, **kwargs)\n",
    "    189 for sleep in sleep_generator:\n",
    "    190     try:\n",
    "--> 191         return target()\n",
    "    193     # pylint: disable=broad-except\n",
    "    194     # This function explicitly must deal with broad exceptions.\n",
    "    195     except Exception as exc:\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1510, in QueryJob.result.<locals>.do_get_result()\n",
    "   1507     self._retry_do_query = retry_do_query\n",
    "   1508     self._job_retry = job_retry\n",
    "-> 1510 super(QueryJob, self).result(retry=retry, timeout=timeout)\n",
    "   1512 # Since the job could already be \"done\" (e.g. got a finished job\n",
    "   1513 # via client.get_job), the superclass call to done() might not\n",
    "   1514 # set the self._query_results cache.\n",
    "   1515 self._reload_query_results(retry=retry, timeout=timeout)\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py:922, in _AsyncJob.result(self, retry, timeout)\n",
    "    919     self._begin(retry=retry, timeout=timeout)\n",
    "    921 kwargs = {} if retry is DEFAULT_RETRY else {\"retry\": retry}\n",
    "--> 922 return super(_AsyncJob, self).result(timeout=timeout, **kwargs)\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/google/api_core/future/polling.py:261, in PollingFuture.result(self, timeout, retry, polling)\n",
    "    256 self._blocking_poll(timeout=timeout, retry=retry, polling=polling)\n",
    "    258 if self._exception is not None:\n",
    "    259     # pylint: disable=raising-bad-type\n",
    "    260     # Pylint doesn't recognize that this is valid in this case.\n",
    "--> 261     raise self._exception\n",
    "    263 return self._result\n",
    "\n",
    "BadRequest: 400 A valid date part name is required but found WEEKDAY at [6:11]\n",
    "\n",
    "Location: US\n",
    "Job ID: 8bd89480-8117-4c27-aacc-c94affe146ca\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95ba94-6f46-46b3-928d-2d5748faf534",
   "metadata": {},
   "source": [
    "### Detect Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8da1dd9d-a43b-4cce-8809-68b156d939f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '\\n'.join(context_query.text.split('\\n')[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d066cbef-f65b-43c5-84bc-a8f1d82f7b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
      "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
      "WHERE \n",
      "  EXTRACT(WEEKDAY FROM starttime) IN (0, 6)\n",
      "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
      "  AND EXTRACT(YEAR FROM starttime) = 2015\n",
      "  AND usertype = 'Subscriber'\n",
      "  AND birth_year < 1955;\n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "eb5e3cc1-0e8b-4099-8574-a55c3c226fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bq.query(query = query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "928f0d6a-7b03-41f2-bd6a-126436c8e99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.cloud.bigquery.job.query.QueryJob"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(query_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bfa68cb5-beb0-4b5a-a7b3-1ccef1185cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'reason': 'invalidQuery',\n",
       "  'location': 'query',\n",
       "  'message': 'A valid date part name is required but found WEEKDAY at [6:11]'}]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_job.errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fa87f-ad51-4c47-80f4-917e2414f7e8",
   "metadata": {},
   "source": [
    "### Use A Chat Model To Iteratively Refine A Query:\n",
    "\n",
    "Chat models, like `codechat-bison@001` are interactive in that they keep a history of the chat session as context for future message interactions.  This is perfect for both generating the initial query and also asking for help with repairing it due to any errors returned from BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6001ffc8-df91-435f-9603-b23bff536524",
   "metadata": {},
   "source": [
    "#### Start A Chat Session With The Same Context (Schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "306d7cff-de29-4889-83c4-3526338509a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "codechat_model = vertexai.language_models.CodeChatModel.from_pretrained('codechat-bison@001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f5d4ebce-07a2-48ea-8241-74ebe0c3392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "codechat = codechat_model.start_chat(\n",
    "    context = f\"\"\"This session is trying to troubleshoot a Google BigQuery SQL query that is being writen to answer the question:\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "BigQuery SQL query that needs to be fixed:\n",
    "{query}\n",
    "\n",
    "The BigQuery Environment has tables defined by the follow schema:\n",
    "{schema_columns.to_markdown(index = False)}\n",
    "\n",
    "Instructions:\n",
    "As the user provides versions of the query and the errors returned by BigQuery, offer suggestions that fix the errors but it is important that the query still answer the original question.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758cd640-1ce3-44b4-96e7-d1efc2dc5826",
   "metadata": {},
   "source": [
    "#### Create a Hint From The Error\n",
    "\n",
    "Use the errors `message` filed to retrieve the line of the query related to the error as a hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "30fa1e80-c578-439a-b007-85a9c0e841c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACT(WEEKDAY FROM starttime) IN (0, 6)\n"
     ]
    }
   ],
   "source": [
    "hint = ''\n",
    "for error in query_job.errors:\n",
    "    # detect error message\n",
    "    if 'message' in list(error.keys()):\n",
    "        # detect index of error location\n",
    "        if error['message'].rindex('[') and error['message'].rindex(']'):\n",
    "            begin = error['message'].rindex('[') + 1\n",
    "            end = error['message'].rindex(']')\n",
    "            # verify that it looks like an error location:\n",
    "            if end > begin and error['message'][begin:end].index(':'):\n",
    "                # retrieve the two parts of the error index: query line, query column\n",
    "                query_index = [int(q) for q in error['message'][begin:end].split(':')]\n",
    "                hint += query.split('\\n')[query_index[0]-1].strip()\n",
    "                break\n",
    "print(hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc472b-9464-48b2-bc38-363e7e1c68fa",
   "metadata": {},
   "source": [
    "#### Fix Query (Try 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6448394d-ac58-47e8-9abd-a743e1e79df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This query:\n",
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
      "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
      "WHERE \n",
      "  EXTRACT(WEEKDAY FROM starttime) IN (0, 6)\n",
      "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
      "  AND EXTRACT(YEAR FROM starttime) = 2015\n",
      "  AND usertype = 'Subscriber'\n",
      "  AND birth_year < 1955;\n",
      "\n",
      "Returns these errors:\n",
      "[{'reason': 'invalidQuery', 'location': 'query', 'message': 'A valid date part name is required but found WEEKDAY at [6:11]'}]\n",
      "\n",
      "Hint, the error appears to be in this line of the query:\n",
      "EXTRACT(WEEKDAY FROM starttime) IN (0, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fix_prompt = f\"\"\"\n",
    "This query:\n",
    "{query}\n",
    "\n",
    "Returns these errors:\n",
    "{query_job.errors}\n",
    "\"\"\"\n",
    "\n",
    "if hint != '':\n",
    "    fix_prompt += f\"\"\"\n",
    "Hint, the error appears to be in this line of the query:\n",
    "{hint}\n",
    "\"\"\"\n",
    "print(fix_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cdff7cd1-efdd-4676-add9-e739450c7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = codechat.send_message(fix_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fc9527a2-f001-481e-b8c3-34fc7b6139e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The following query fixes the error:\n",
       "\n",
       "```\n",
       "SELECT COUNT(*) AS num_trips\n",
       "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
       "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
       "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
       "WHERE \n",
       "  DATE(starttime) BETWEEN '2015-01-01' AND '2015-12-31'\n",
       "  AND EXTRACT(DAYOFWEEK FROM starttime) IN (0, 6)\n",
       "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
       "  AND usertype = 'Subscriber'\n",
       "  AND birth_year < 1955;\n",
       "```\n",
       "\n",
       "The error was caused by the use of the `WEEKDAY` function, which is not supported in BigQuery. The `DATE` function can be used to extract the date from a timestamp, and the `DAYOFWEEK` function can be used to extract the day of the week from a date."
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "66bf5248-8a4d-44e2-8068-ad519d3cd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = codechat.send_message(f'Respond with only the corrected query as a markdown code block.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7d975cdf-2ea8-467c-94c8-59879b148527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "```\n",
       "SELECT COUNT(*) AS num_trips\n",
       "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
       "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
       "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
       "WHERE \n",
       "  DATE(starttime) BETWEEN '2015-01-01' AND '2015-12-31'\n",
       "  AND EXTRACT(DAYOFWEEK FROM starttime) IN (0, 6)\n",
       "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
       "  AND usertype = 'Subscriber'\n",
       "  AND birth_year < 1955;\n",
       "```"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "244d4d02-1548-42fc-ae09-e15b1270a7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
      "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
      "WHERE \n",
      "  DATE(starttime) BETWEEN '2015-01-01' AND '2015-12-31'\n",
      "  AND EXTRACT(DAYOFWEEK FROM starttime) IN (0, 6)\n",
      "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
      "  AND usertype = 'Subscriber'\n",
      "  AND birth_year < 1955;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if response.text.find(\"```\") >= 0:\n",
    "    query = response.text.split(\"```\")[1]\n",
    "    if query.startswith('sql'): query = query[3:]\n",
    "    print(query)\n",
    "else:\n",
    "    print('no query in response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f3854b69-7d13-45b3-98f8-c1a5e4646806",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bq.query(query = query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "686bbb99-e65b-4add-9c1a-461dc615e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job.errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9bb91720-4cdd-439b-8ca4-e4f925ff8ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_trips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_trips\n",
       "0      18968"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c14f3-7dfe-4581-a130-ceb76a2e0cae",
   "metadata": {},
   "source": [
    "#### Generate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5b64c24e-6bbf-470a-aa4b-2334a2111cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18968\n"
     ]
    }
   ],
   "source": [
    "question_prompt = f\"\"\"\n",
    "Answer the following question using the provided context.  Note that the context is a tabular result returned from a BigQuery query.  Do not repeat the question or the context when responding.\n",
    "\n",
    "question:\n",
    "{question}\n",
    "\n",
    "context:\n",
    "{query_job.to_dataframe().to_markdown(index = False)}\n",
    "\"\"\"\n",
    "\n",
    "question_response = textgen_model.predict(question_prompt, max_output_tokens = 500)\n",
    "\n",
    "print(question_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a003c18f-18e2-4788-8e02-2005b6ea406b",
   "metadata": {},
   "source": [
    "### Put It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "cfab1694-e72e-45c8-bf82-f88576d31805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many trips were started on a weekend, in the afternoon, during 2015, by a regular rider, who is over the age of 60?'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26273c9c-4f62-4006-b21f-6654a2c489bd",
   "metadata": {},
   "source": [
    "#### Functions To Answer The Question Using Iteration To Fix Context Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "e74c4816-7527-4c0b-872e-32cef77a88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_query(question, schema_columns):\n",
    "    \n",
    "    # code generation model\n",
    "    codegen_model = vertexai.language_models.CodeGenerationModel.from_pretrained('code-bison')\n",
    "    \n",
    "    # initial request for query:\n",
    "    query_response = codegen_model.predict(f\"\"\"Write a Google SQL query for BigQuery that answers the following question while correctly refering to BigQuery tables and the needed column names.  When joining tables use coersion to ensure all join columns are the same data type. Output column names should include the units when applicable.  Tables should be refered to using a fully qualified name include project and dataset along with table name. \n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context:\n",
    "{schema_columns.to_markdown(index = False)}\n",
    "\"\"\")\n",
    "    \n",
    "    # extract query from response\n",
    "    if query_response.text.find(\"```\") >= 0:\n",
    "        query = query_response.text.split(\"```\")[1]\n",
    "        if query.startswith('sql'):\n",
    "            query = query[3:]\n",
    "        print('First try:\\n', query)\n",
    "    else:\n",
    "        print('No query provided (first try) - unforseen error, printing out response to help with editing this funcntion:\\n', query_response.text)\n",
    "    \n",
    "    return query    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "dd3317ce-9c1e-40cf-a8a0-4ef60cb9ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codechat_start(question, query, schema_columns):\n",
    "\n",
    "    # code chat model\n",
    "    codechat_model = vertexai.language_models.CodeChatModel.from_pretrained('codechat-bison@001')\n",
    "    \n",
    "    # start a code chat session and give the schema for columns as the starting context:\n",
    "    codechat = codechat_model.start_chat(\n",
    "        context = f\"\"\"This session is trying to troubleshoot a Google BigQuery SQL query that is being writen to answer a question.\n",
    "Question: {question}\n",
    "\n",
    "BigQuery SQL Query: {query}\n",
    "\n",
    "information_schema:\n",
    "{schema_columns.to_markdown(index = False)}\n",
    "\n",
    "Instructions:\n",
    "As the user provides versions of the query and the errors returned by BigQuery, offer suggestions that fix the errors but it is important that the query still answer the original question.\n",
    "\"\"\"\n",
    "    )\n",
    "    \n",
    "    return codechat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "0b156579-6921-46ad-9120-99bc70cc5942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_query(query, max_fixes):\n",
    "    \n",
    "    # iteratively run query, and fix it using codechat until success (or max_fixes reached):\n",
    "    fix_tries = 0\n",
    "    answer = False\n",
    "    while fix_tries < max_fixes:\n",
    "        if not query: \n",
    "            return\n",
    "        # run query:\n",
    "        query_job = bq.query(query = query)\n",
    "        # if errors, then generate repair query:\n",
    "        if query_job.errors:\n",
    "            fix_tries += 1\n",
    "            \n",
    "            if fix_tries == 1:\n",
    "                codechat = codechat_start(question, query, schema_columns)\n",
    "            \n",
    "            # construct hint from error\n",
    "            hint = ''\n",
    "            for error in query_job.errors:\n",
    "                # detect error message\n",
    "                if 'message' in list(error.keys()):\n",
    "                    # detect index of error location\n",
    "                    if error['message'].rindex('[') and error['message'].rindex(']'):\n",
    "                        begin = error['message'].rindex('[') + 1\n",
    "                        end = error['message'].rindex(']')\n",
    "                        # verify that it looks like an error location:\n",
    "                        if end > begin and error['message'][begin:end].index(':'):\n",
    "                            # retrieve the two parts of the error index: query line, query column\n",
    "                            query_index = [int(q) for q in error['message'][begin:end].split(':')]\n",
    "                            hint += query.split('\\n')[query_index[0]-1].strip()\n",
    "                            break\n",
    "            \n",
    "            # construct prompt to request a fix:\n",
    "            fix_prompt = f\"\"\"This query:\\n{query}\\n\\nReturns these errors:\\n{query_job.errors}\\n\\nPlease fix it and make sure it matches the schema.\"\"\"\n",
    "\n",
    "            #if hint != '':\n",
    "            #    fix_prompt += f\"\"\"Hint, the error appears to be in this line of the query:\\n{hint}\"\"\"            \n",
    "            \n",
    "            query_response = codechat.send_message(fix_prompt)\n",
    "            query_response = codechat.send_message('Respond with only the corrected query that still answers the question as a markdown code block.')\n",
    "            if query_response.text.find(\"```\") >= 0:\n",
    "                query = query_response.text.split(\"```\")[1]\n",
    "                if query.startswith('sql'):\n",
    "                    query = query[4:]\n",
    "                print(f'Fix #{fix_tries}:\\n', query)\n",
    "            # response did not have a query????:\n",
    "            else:\n",
    "                query = ''\n",
    "                print('No query in response...')\n",
    "\n",
    "        # no error, break while loop\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return query, query_job, fix_tries, codechat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "044962e0-2e7d-4a81-ada5-f170d3bb09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, query_job):\n",
    "\n",
    "    # text generation model\n",
    "    textgen_model = vertexai.language_models.TextGenerationModel.from_pretrained('text-bison')\n",
    "\n",
    "    result = query_job.to_dataframe()\n",
    "    # answer question\n",
    "    question_prompt = f\"\"\"Answer the following question using the provided context.  Note that the context is a tabular result returned from a BigQuery query.  Do not repeat the question or the context when responding.\n",
    "\n",
    "question:\n",
    "{question}\n",
    "context:\n",
    "{result.to_markdown(index = False)}\n",
    "\"\"\"\n",
    "    question_response = textgen_model.predict(question_prompt, max_output_tokens = 500)\n",
    "    \n",
    "    return question_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5e6272eb-9ceb-4511-b90f-00dcb4dd381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BQ_QA(question, max_fixes = 7, schema_columns = schema_columns):\n",
    "    \n",
    "    query = initial_query(question, schema_columns)\n",
    "    # run query:\n",
    "    query_job = bq.query(query = query)\n",
    "    # if errors, then generate repair query:\n",
    "    if query_job.errors:\n",
    "        query, query_job, fix_tries, codechat = fix_query(query, max_fixes)\n",
    "    \n",
    "    # respond with outcome:\n",
    "    if query_job.errors:\n",
    "        print(f'No answer generated after {fix_tries} tries.')\n",
    "        return codechat\n",
    "    else:\n",
    "        question_response = answer_question(question, query_job)\n",
    "        print(question_response)\n",
    "        try:\n",
    "            return codechat\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "7feaea48-6f32-44c0-9170-90ac62f28866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First try:\n",
      " \n",
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
      "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
      "WHERE \n",
      "  EXTRACT(WEEKDAY FROM starttime) IN (0, 6)\n",
      "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
      "  AND EXTRACT(YEAR FROM starttime) = 2015\n",
      "  AND usertype = \"Subscriber\"\n",
      "  AND birth_year < 1955;\n",
      "\n",
      "Fix #1:\n",
      " \n",
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
      "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
      "WHERE \n",
      "  DATE(starttime) BETWEEN '2015-01-01' AND '2015-12-31'\n",
      "  AND EXTRACT(WEEKDAY FROM DATE(starttime)) IN (0, 6)\n",
      "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
      "  AND usertype = \"Subscriber\"\n",
      "  AND birth_year < 1955;\n",
      "\n",
      "Fix #2:\n",
      " \n",
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
      "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
      "WHERE \n",
      "  DATE(starttime) BETWEEN '2015-01-01' AND '2015-12-31'\n",
      "  AND EXTRACT(DAYOFWEEK FROM starttime) IN (0, 6)\n",
      "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
      "  AND usertype = \"Subscriber\"\n",
      "  AND birth_year < 1955;\n",
      "\n",
      " 18968\n"
     ]
    }
   ],
   "source": [
    "session = BQ_QA(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "bfd2455e-1c13-4a50-b074-0facb4121f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This query:\n",
      "\n",
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
      "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
      "WHERE \n",
      "  EXTRACT(WEEKDAY FROM starttime) IN (0, 6)\n",
      "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
      "  AND EXTRACT(YEAR FROM starttime) = 2015\n",
      "  AND usertype = \"Subscriber\"\n",
      "  AND birth_year < 1955;\n",
      "\n",
      "\n",
      "Returns these errors:\n",
      "[{'reason': 'invalidQuery', 'location': 'query', 'message': 'A valid date part name is required but found WEEKDAY at [7:11]'}]\n",
      "\n",
      "Please fix it and make sure it matches the schema.\n",
      "The query is not valid because the `WEEKDAY` function is not supported for the `starttime` field. The `starttime` field is a `TIMESTAMP` field, and the `WEEKDAY` function is only supported for `DATE` fields.\n",
      "\n",
      "To fix the query, you can use the `DATE` function to convert the `starttime` field to a `DATE` field. Then, you can use the `WEEKDAY` function on the `DATE` field.\n",
      "\n",
      "Here is the fixed query:\n",
      "\n",
      "```\n",
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
      "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
      "WHERE \n",
      "  DATE(starttime) BETWEEN '2015-01-01' AND '2015-12-31'\n",
      "  AND EXTRACT(WEEKDAY FROM DATE(starttime)) IN (0, 6)\n",
      "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
      "  AND usertype = \"Subscriber\"\n",
      "  AND birth_year < 1955;\n",
      "```\n",
      "\n",
      "This query will count the number of trips that were started on a weekend, in the afternoon, during 2015, by a regular rider, who is over the age of 60.\n",
      "Respond with only the corrected query that still answers the question as a markdown code block.\n",
      "```\n",
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
      "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
      "WHERE \n",
      "  DATE(starttime) BETWEEN '2015-01-01' AND '2015-12-31'\n",
      "  AND EXTRACT(WEEKDAY FROM DATE(starttime)) IN (0, 6)\n",
      "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
      "  AND usertype = \"Subscriber\"\n",
      "  AND birth_year < 1955;\n",
      "```\n",
      "This query:\n",
      "\n",
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
      "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
      "WHERE \n",
      "  DATE(starttime) BETWEEN '2015-01-01' AND '2015-12-31'\n",
      "  AND EXTRACT(WEEKDAY FROM DATE(starttime)) IN (0, 6)\n",
      "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
      "  AND usertype = \"Subscriber\"\n",
      "  AND birth_year < 1955;\n",
      "\n",
      "\n",
      "Returns these errors:\n",
      "[{'reason': 'invalidQuery', 'location': 'query', 'message': 'A valid date part name is required but found WEEKDAY at [8:15]'}]\n",
      "\n",
      "Please fix it and make sure it matches the schema.\n",
      "The query is not valid because the `WEEKDAY` function is not supported for the `DATE` field. The `DATE` field is a `DATE` field, and the `WEEKDAY` function is only supported for `TIMESTAMP` fields.\n",
      "\n",
      "To fix the query, you can use the `EXTRACT` function to extract the day of the week from the `starttime` field. Then, you can use the `IN` operator to compare the day of the week to the values `0` and `6`.\n",
      "\n",
      "Here is the fixed query:\n",
      "\n",
      "```\n",
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
      "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
      "WHERE \n",
      "  DATE(starttime) BETWEEN '2015-01-01' AND '2015-12-31'\n",
      "  AND EXTRACT(DAYOFWEEK FROM starttime) IN (0, 6)\n",
      "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
      "  AND usertype = \"Subscriber\"\n",
      "  AND birth_year < 1955;\n",
      "```\n",
      "Respond with only the corrected query that still answers the question as a markdown code block.\n",
      "```\n",
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS stations\n",
      "ON CAST(trips.start_station_id AS STRING) = stations.station_id\n",
      "WHERE \n",
      "  DATE(starttime) BETWEEN '2015-01-01' AND '2015-12-31'\n",
      "  AND EXTRACT(DAYOFWEEK FROM starttime) IN (0, 6)\n",
      "  AND EXTRACT(HOUR FROM starttime) BETWEEN 12 AND 17\n",
      "  AND usertype = \"Subscriber\"\n",
      "  AND birth_year < 1955;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "for message in session.message_history:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f035a7-d5fa-4651-96da-5ce02322137c",
   "metadata": {},
   "source": [
    "### Try Another Question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "5ad8a9b0-52fe-4b05-8d5a-fd3136ac1d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First try:\n",
      " \n",
      "SELECT COUNT(*) AS num_trips\n",
      "FROM bigquery-public-data.new_york.citibike_trips AS trips\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS start_stations\n",
      "ON CAST(trips.start_station_id AS STRING) = start_stations.station_id\n",
      "JOIN bigquery-public-data.new_york.citibike_stations AS end_stations\n",
      "ON CAST(trips.end_station_id AS STRING) = end_stations.station_id\n",
      "WHERE EXTRACT(HOUR FROM trips.starttime) BETWEEN 18 AND 23\n",
      "AND trips.tripduration > 3600\n",
      "AND trips.usertype = \"Subscriber\"\n",
      "AND EXTRACT(YEAR FROM trips.starttime) = 2015\n",
      "AND trips.birth_year < 1955;\n",
      "\n",
      " 180\n"
     ]
    }
   ],
   "source": [
    "session = BQ_QA('How many trips during the year 2015: started in the evening, were over an hour long, and were by regular riders, who were over age 60?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0828f8db-fc1f-4c29-89e0-4f2ab12e44b1",
   "metadata": {},
   "source": [
    "### Ideas For Improvement\n",
    "\n",
    "After a few attempts to fix, ask the CodeChat LLM to start fresh and write a new query to answer the question.  The iterate on the new query.\n",
    "\n",
    "If the fixes are actually breaking the logic of the query try asking if the successful query answers the questions before providing the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc2d7ef-e34d-4400-9059-1e2b59cad598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457832d1-7334-4bdf-bc21-a81fe4495714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ebba2-0eeb-40d5-b292-8d664234d6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba9cc6-2b1e-4058-88fa-d36b89e12537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d2e00-d55b-4c2d-b440-07d22117de94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aeb321-5a73-4f3d-ade4-6b640dd221a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae38a3d-c5cb-4ccf-b7fb-6768be1612c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e159b35f-3046-41ab-89e6-9a7c2ba9d0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e00e72-01c2-444b-a933-87b6d572ea11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
